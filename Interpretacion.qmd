# Visualizar la decisión del clasificador


Aqui se utiliza Class Activation Maps (CAM) para visualizar las regiones más importantes de una radiografía al tomar la decisión de si un paciente tiene neumonía o no. Este tipo de visualización es útil para entender cómo un modelo convolucional como ResNet toma decisiones basadas en los patrones presentes en las imágenes.

(https://arxiv.org/abs/1512.04150).



```{python}
#| echo: false
#| results: hide
%matplotlib inline

import torch
import torchvision
from torchvision import transforms
import numpy as np
import matplotlib.pyplot as plt
import pytorch_lightning as pl
```

```{python}
#| echo: false
#| results: hide
def load_file(path):
    return np.load(path).astype(np.float32)
```

```{python}
#| echo: false
#| results: hide
val_transforms = transforms.Compose([
                                transforms.ToTensor(),
                                transforms.Normalize(0.49, 0.248),

])

val_dataset = torchvision.datasets.DatasetFolder("/Users/davidescudero/Library/Mobile Documents/com~apple~CloudDocs/Documents/Github/diplomadoIA24/Processed/val", loader=load_file, extensions="npy", transform=val_transforms)
```

## CAM
El objetivo de CAM es visualizar las regiones más importantes de la imagen que influenciaron la decisión del clasificador. El mapa de activación $M$ se calcula utilizando la siguiente fórmula:
$$ M = \sum_k w_kA_k$$

Donde:

$A_k$ es la salida del último bloque convolucional (es decir, los mapas de características).

$w_k$ son los pesos asociados de la capa completamente conectada (fully connected).

## VIsualizacion de la Arquitectura de ResNet18

```{python}
#| echo: false
temp_model = torchvision.models.resnet18()
temp_model
```

**ResNet18**: Se utiliza como el modelo de base. Aquí, se extraen todas las capas convolucionales antes de la capa de average pooling. Esto es porque queremos acceder a los mapas de características generados por la última capa convolucional para visualizar qué parte de la imagen influyó más en la decisión del modelo.

```{python}
#| echo: false
#| results: hide
list(temp_model.children())[:-2]  # get all layers up to avgpool
```

## Modificación del Modelo para CAM

- Modificación de ResNet18: Se ajusta la primera capa convolucional para aceptar imágenes de un solo canal (escala de grises), ya que las radiografías no son imágenes RGB. Además, la capa completamente conectada (fc) se modifica para tener una sola salida, ya que este es un problema de clasificación binaria.

- feature_map: Almacena los mapas de características (features) generados por la última capa convolucional. Estos son esenciales para calcular el CAM.

```{python}
#| echo: false
#| results: hide
torch.nn.Sequential(*list(temp_model.children())[:-2])
```

```{python}
#| echo: false
#| results: hide
class PneumoniaModel(pl.LightningModule):
    def __init__(self):
        super().__init__()
        
        self.model = torchvision.models.resnet18()
        # Change conv1 from 3 to 1 input channels
        self.model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
        # Change out_feature of the last fully connected layer (called fc in resnet18) from 1000 to 1
        self.model.fc = torch.nn.Linear(in_features=512, out_features=1)
        
        # Extract the feature map
        self.feature_map = torch.nn.Sequential(*list(self.model.children())[:-2])    
    def forward(self, data):
        
        # Compute feature map
        feature_map = self.feature_map(data)
        # Use Adaptive Average Pooling as in the original model
        avg_pool_output = torch.nn.functional.adaptive_avg_pool2d(input=feature_map, output_size=(1, 1))
        print(avg_pool_output.shape)
        # Flatten the output into a 512 element vector
        avg_pool_output_flattened = torch.flatten(avg_pool_output)
        print(avg_pool_output_flattened.shape)
        # Compute prediction
        pred = self.model.fc(avg_pool_output_flattened)
        return pred, feature_map
```

```{python}
def cam(model, img):
    with torch.no_grad():
        pred, features = model(img.unsqueeze(0))
    features = features.reshape((512, 49))
    weight_params = list(model.model.fc.parameters())[0]
    weight = weight_params[0].detach()
    
    
    cam = torch.matmul(weight, features)
    cam_img = cam.reshape(7, 7).cpu()
    return cam_img, torch.sigmoid(pred)
```

```{python}
#| echo: false
#| results: hide
# Use strict to prevent pytorch from loading weights for self.feature_map
model = PneumoniaModel.load_from_checkpoint("/Users/davidescudero/Library/Mobile Documents/com~apple~CloudDocs/Documents/Github/diplomadoIA24/04-Pneumonia-Classification/weights/weights_3.ckpt", strict=False)
model.eval();
```

## CAM
```{python}
#| echo: false
#| results: hide
def cam(model, img):
    """
    Compute class activation map according to cam algorithm
    """
    with torch.no_grad():
        pred, features = model(img.unsqueeze(0))
    b, c, h, w = features.shape

    # We reshape the 512x7x7 feature tensor into a 512x49 tensor in order to simplify the multiplication
    features = features.reshape((c, h*w))
    
    # Get only the weights, not the bias
    weight_params = list(model.model.fc.parameters())[0] 
    
    # Remove gradient information from weight parameters to enable numpy conversion
    weight = weight_params[0].detach()
    print(weight.shape)
    # Compute multiplication between weight and features with the formula from above.
    # We use matmul because it directly multiplies each filter with the weights
    # and then computes the sum. This yields a vector of 49 (7x7 elements)
    cam = torch.matmul(weight, features)
    print(features.shape)
    
  ############################################################
    
    # Normalize and standardize the class activation map (Not always necessary, thus not shown in the lecture)
    cam = cam - torch.min(cam)
    cam_img = cam / torch.max(cam)
    # Reshape the class activation map to 512x7x7 and move the tensor back to CPU
    cam_img = cam_img.reshape(h, w).cpu()

    return cam_img, torch.sigmoid(pred)

def visualize(img, heatmap, pred):
    """
    Visualization function for class activation maps
    """
    img = img[0]
    # Resize the activation map of size 7x7 to the original image size (224x224)
    heatmap = transforms.functional.resize(heatmap.unsqueeze(0), (img.shape[0], img.shape[1]))[0]
    
    # Create a figure
    fig, axis = plt.subplots(1, 2)
    
    axis[0].imshow(img, cmap="bone")
    # Overlay the original image with the upscaled class activation map
    axis[1].imshow(img, cmap="bone")
    axis[1].imshow(heatmap, alpha=0.5, cmap="jet")
    plt.title(f"Pneumonia: {(pred > 0.5).item()}")
```


```{python}
#| echo: false
#| results: hide
def visualize(img, cam, pred):
    img = img[0]
    cam = transforms.functional.resize(cam.unsqueeze(0), (224, 224))[0]
    
    fig, axis = plt.subplots(1, 2)
    axis[0].imshow(img, cmap="bone")
    axis[1].imshow(img, cmap="bone")
    axis[1].imshow(cam, alpha=0.5, cmap="jet")
    plt.title(pred)
```

```{python}
#| echo: false
#| results: hide
img = val_dataset[-6][0]  # Select a subject
activation_map, pred = cam(model, img)  # Compute the Class activation map given the subject
```

```{python}
#| echo: false
visualize(img, activation_map, pred)  # Visualize CAM
```

- Izquierda: La radiografía original.
- Derecha: La radiografía con el mapa de activación superpuesto. Las áreas más rojas son las que el modelo considera más relevantes para hacer su predicción. Esto ayuda a entender cómo el modelo clasifica a partir de las características aprendidas.