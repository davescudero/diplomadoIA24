[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Módulos 5 y 6",
    "section": "",
    "text": "Temario y referencias\nTodo el material y las notas de este modulo estarán disponibles en este repositorio.\n\nPlanteamiento estratégico y presentación de proyectos de IA en salud\n\nIntroducción a la inteligencia artificial en salud\nImportancia de la planificación estratégica en proyectos de IA\nEjemplo práctico: Clasificación de neumonías con deep learning\nHerramientas para la presentación de proyectos\n\nColaboración interdisciplinaria en proyectos de IA\n\nRoles y competencias en equipos de IA\nEstrategias para la colaboración interdisciplinaria\nDesafíos y soluciones en la implementación de proyectos de IA en salud\n\nImplementación y seguimiento de proyectos de IA\n\nGestión de proyectos en el contexto de salud\nMantenimiento y monitoreo de modelos de IA\nÉtica y regulación en la inteligencia artificial aplicada a la salud\n\nObtención, análisis y preparación de datos\n\nFuentes de datos en el sector salud\nProcesamiento y limpieza de datos\nTécnicas avanzadas de preparación de datos para IA\n\nEvaluación y optimización de modelos de IA\n\nMétricas de evaluación de modelos en salud\nOptimización de modelos: Técnicas y herramientas\nConsideraciones sobre sesgos y limitaciones en modelos de IA\n\nSesgos y limitaciones en la inteligencia artificial\n\nIdentificación de sesgos en datos y modelos\nImpacto de los sesgos en los resultados clínicos\nEstrategias para mitigar sesgos en IA\n\n\n\nMaterial\nEl material del curso, incluyendo ejemplos, referencias y ejercicios, estará disponible en este repositorio.\n\n\nReferencias principales\n\nArtificial Intelligence in Healthcare, (chang2019artificial?)\nMachine Learning for Healthcare, (aggarwal2020machine?)\nDeep Learning, (goodfellow2016?)\n\n\n\nOtras referencias\n\nData Science for Medical Imaging, (de2019data?)\nThe Elements of Statistical Learning, (ESL?)\nIntroduction to Machine Learning with Python, (muller2016introduction?)\n\n\n\nSoftware\nPara las tareas y proyectos pueden usar cualquier lenguaje o flujo de trabajo que prefieran (R, Python, etc.), siempre y cuando el trabajo esté basado en código y no en point-and-click. Se recomienda el uso de librerías especializadas y multiplataforma (como PyTorch, TensorFlow, o Scikit-learn).",
    "crumbs": [
      "Temario y referencias"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introducción",
    "section": "",
    "text": "1.1 Objetivos del Proyecto\nDesarrollo de un Modelo de Clasificación: En las entrañas de este proyecto se encuentra el desarrollo de un modelo de deep learning capaz de discernir entre una radiografía normal y una afectada por neumonía. Con cada imagen procesada, el sistema podría aprender, mejorar y adaptarse, buscando alcanzar un nivel de precisión aceptable.\nEvaluación de Desempeño: Pero construir un modelo no es suficiente. Necesitamos asegurarnos de que este modelo funcione en el mundo real, donde las condiciones pueden ser mucho más caóticas que en un entorno de laboratorio. Por ello, el desempeño del sistema se evaluara utilizando métricas clave, sin embrago se tendría que comparar con la interpretación humana para asegurarnos de que sea una herramienta útil y fiable.\nImplementación Clínica: Imagina un futuro cercano donde este modelo no sea solo un concepto en un laboratorio, sino una herramienta de uso diario en hospitales y clínicas. Aprenderemos estrategias para integrar el sistema en la práctica clínica, garantizando que sea fácil de usar y accesible para el personal médico.\nEn la radiología, la IA está comenzando a desempeñar un papel crucial, ayudando a los médicos a detectar anomalías con mayor precisión y a reducir la posibilidad de errores humanos.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "intro.html#contexto",
    "href": "intro.html#contexto",
    "title": "1  Introducción",
    "section": "",
    "text": "IBM debería dejar de intentar curar el cáncer. Liberaron el motor de marketing sin controlar cómo construir y desarrollar un producto. Peter Greulich",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "intro.html#objetivos-del-proyecto",
    "href": "intro.html#objetivos-del-proyecto",
    "title": "1  Introducción",
    "section": "1.2 Objetivos del Proyecto",
    "text": "1.2 Objetivos del Proyecto\nEste proyecto tiene una misión clara: desarrollar una herramienta que no solo sea tecnológicamente avanzada, sino también clínicamente relevante. El objetivo es construir un sistema de IA que ayude a los médicos en su toma de decisiones, aportando una segunda opinión basada en datos que pueda confirmar o cuestionar un diagnóstico inicial.\nDesarrollo de un Modelo de Clasificación: En las entrañas de este proyecto se encuentra el desarrollo de un modelo de deep learning capaz de discernir entre una radiografía normal y una afectada por neumonía. Con cada imagen procesada, el sistema aprende, mejora y se adapta, buscando alcanzar un nivel de precisión aceptable.\nEvaluación de Desempeño: Pero construir un modelo no es suficiente. Necesitamos asegurarnos de que este modelo funcione en el mundo real, donde las condiciones pueden ser mucho más caóticas que en un entorno de laboratorio. Por ello, evaluaremos el desempeño del sistema utilizando métricas clave, y lo compararemos con la interpretación humana para asegurarnos de que sea una herramienta útil y fiable.\nImplementación Clínica: Imagina un futuro cercano donde este modelo no sea solo un concepto en un laboratorio, sino una herramienta de uso diario en hospitales y clínicas. Diseñaremos estrategias para integrar el sistema en la práctica clínica, garantizando que sea fácil de usar y accesible para el personal médico.\nConsideraciones Éticas y Legales: Finalmente, en un mundo donde la privacidad de los datos y la ética en la IA están bajo escrutinio constante, abordaremos las cuestiones éticas y legales, asegurándonos de que el sistema respete la confidencialidad de los pacientes y cumpla con las regulaciones sanitarias .\nLa inteligencia artificial no es solo una herramienta; es un cambio de paradigma en la medicina. Piensa en la IA como un nuevo colega en el equipo médico, uno que nunca se cansa, que no se distrae, y que puede revisar cientos de imágenes en el tiempo que a un humano le llevaría revisar unas pocas. En la radiología, la IA está comenzando a desempeñar un papel crucial, ayudando a los médicos a detectar anomalías con mayor precisión y a reducir la posibilidad de errores humanos.\nLa implementación de IA en la detección de neumonía es un paso hacia un futuro donde el diagnóstico es más rápido, más preciso y más accesible para todos. No se trata solo de mejorar la eficiencia; se trata de salvar vidas. Al integrar estas tecnologías en la práctica clínica, no solo mejoramos los resultados para los pacientes, sino que también allanamos el camino para futuras innovaciones que seguirán revolucionando la medicina.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "plan-estrategico.html",
    "href": "plan-estrategico.html",
    "title": "2  Planteamiento Estratégico",
    "section": "",
    "text": "2.1 Estrategia para IA vs. Estrategia con IA\nEstrategia para IA: Preparación de una organización para implementar la IA. - Inversión en tecnologías de IA - Capacitación del personal - Adquisición de datos - Diseño de procesos que permitan a la IA integrarse en el flujo de trabajo.\nEstrategia con IA: Cómo se usa la IA para lograr sus objetivos estratégicos más amplios.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Planteamiento Estratégico</span>"
    ]
  },
  {
    "objectID": "plan-estrategico.html#introducción",
    "href": "plan-estrategico.html#introducción",
    "title": "2  Planteamiento Estratégico",
    "section": "",
    "text": "2.1.1 Estrategia para IA vs. Estrategia con IA\nAquí es donde surge la diferencia entre una estrategia para IA y una estrategia con IA. Una estrategia para IA se refiere a cómo una organización se prepara para implementar la IA. Esto incluye la inversión en tecnologías de IA, la capacitación del personal, la adquisición de datos, y el diseño de procesos que permitan a la IA integrarse en el flujo de trabajo.\nPor otro lado, una estrategia con IA se refiere a cómo una organización utiliza la IA para lograr sus objetivos estratégicos más amplios. Aquí la IA no es solo una herramienta adicional; se convierte en un componente integral del proceso de toma de decisiones y ejecución de la estrategia de la organización.\nConsideremos un hospital que busca mejorar los resultados clínicos y la experiencia del paciente. Una estrategia para IA podría implicar la adquisición de sistemas de IA para la interpretación de imágenes médicas, la capacitación de los radiólogos en el uso de estos sistemas, y la integración de estos resultados en el expediente clínico electrónico.\nSin embargo, una estrategia con IA iría más allá, integrando la IA en la estrategia operativa del hospital para optimizar el flujo de pacientes en la sala de urgencias, reduciendo los tiempos de espera y mejorando la satisfacción del paciente. Aquí, la IA no solo se usa como una herramienta, sino que se convierte en una parte integral de cómo el hospital opera y cumple sus objetivos estratégicos, como mejorar la calidad de la atención y la eficiencia operativa.\n\n\n2.1.2 El Papel de los KPIs\nEn el sector salud, la estrategia debe entenderse como la forma en que las organizaciones gestionan y priorizan su cartera de Indicadores Clave de Rendimiento (KPIs). Estos pueden incluir la tasa de mortalidad, la tasa de readmisiones, la satisfacción del paciente, entre otros. No se trata simplemente de optimizar KPIs individuales, sino de comprender cómo interactúan y se afectan mutuamente.\nPor ejemplo, maximizar la eficiencia en las intervenciones quirúrgicas no puede hacerse a expensas de la calidad de la atención postoperatoria. Los modelos de IA pueden ayudar a los hospitales a lograr un equilibrio óptimo entre estos KPIs, asegurando que, por ejemplo, las intervenciones para reducir los costos no disminuyan la calidad de la atención. Sin embargo, es fundamental que los líderes del sector salud mantengan una supervisión constante, asegurándose de que las decisiones impulsadas por la IA estén alineadas con los valores y objetivos éticos de la organización.\n\n\n2.1.3 El Papel Esencial de los Datos\nNo existe una estrategia efectiva para la IA sin una estrategia sólida para los datos. La calidad, volumen y velocidad de los datos son cruciales para entrenar modelos de IA que puedan, por ejemplo, predecir brotes de enfermedades o personalizar planes de tratamiento para pacientes crónicos. Los hospitales y sistemas de salud deben invertir en gobernanza de datos, asegurando que los datos recopilados sean precisos, completos y se utilicen de manera efectiva para mejorar la atención.\nDesafortunadamente, muchos sistemas de salud todavía no han alineado sus estrategias de datos con sus iniciativas de IA. Aunque se reconoce que la IA es fundamental para la transformación digital en salud, pocos sistemas han implementado estrategias de gobernanza de datos robustas. Esta desconexión limita el potencial de la IA para mejorar la atención al paciente y optimizar los procesos operativos.\n\n\n2.1.4 Un Medio para un Fin\nAl igual que las innovaciones pasadas en el sector salud, como la introducción de antibióticos o las vacunas, la IA tiene el potencial de transformar profundamente la manera en que se presta atención médica. Sin embargo, la IA debe verse como un medio para alcanzar fines específicos, como mejorar los resultados de los pacientes, reducir costos y aumentar la eficiencia operativa.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Planteamiento Estratégico</span>"
    ]
  },
  {
    "objectID": "plan-estrategico.html#planeacion-del-proyecto",
    "href": "plan-estrategico.html#planeacion-del-proyecto",
    "title": "2  Planteamiento Estratégico",
    "section": "2.2 Planeacion del proyecto",
    "text": "2.2 Planeacion del proyecto\n\n2.2.1 ¿Cómo inicio?\nPara comenzar a planear un proyecto de inteligencia artificial, podemos seguir un enfoque basado en las cuatro fases fundamentales delineadas por Gartner:\nEstablecer la Visión del Proyecto de IA\nDefinir claramente cómo el proyecto de IA para la clasificación de neumonías contribuirá a los objetivos generales de la organización. Es crucial establecer desde el inicio cuál es el impacto esperado en términos de precisión diagnóstica, eficiencia en el flujo de trabajo clínico y mejora de los resultados para los pacientes.\n“Nuestro proyecto de IA se enfoca en implementar un sistema de clasificación automatizada de neumonías, con el objetivo de reducir el tiempo de diagnóstico en un 50% y mejorar la precisión diagnóstica en un 20%, en comparación con las evaluaciones manuales, utilizando redes neuronales convolucionales (CNN) entrenadas con imágenes de rayos X de tórax.”\nIdentificar Barreras Organizacionales y Soluciones\nIdentificar y eliminar las barreras que podrían impedir el éxito del proyecto. Esto puede incluir desafíos tecnológicos, falta de habilidades en el equipo, resistencia al cambio, o cuestiones regulatorias.\n“Una de las barreras que enfrentaremos es la integración del modelo de IA en los flujos de trabajo clínicos existentes. Para superarlo, desarrollaremos un piloto inicial en colaboración con un grupo reducido de radiólogos y técnicos de TI, que nos permitirá iterar sobre el modelo y su implementación, asegurando que se ajuste a las necesidades clínicas y cumpla con las normativas vigentes.”\nEvaluar y Mitigar Riesgos\nEvaluar los riesgos asociados al proyecto, incluyendo los regulatorios, reputacionales, tecnológicos y relacionados con la competencia. Definir acciones para mitigar estos riesgos.\n“Para mitigar el riesgo de sesgos en nuestro modelo de clasificación, implementaremos un proceso de revisión continua, donde se analizarán los resultados del modelo en subgrupos de pacientes diferenciados por edad, sexo y comorbilidades. Además, trabajaremos con expertos en ética y regulaciones para garantizar que el sistema cumpla con las normas de equidad y no discriminación.”\nPriorizar Iniciativas Viables y de Alto Valor\nDeterminar qué iniciativas de IA son tanto valiosas como factibles, y priorizarlas en función de su alineación con los objetivos del negocio, la viabilidad técnica y la capacidad organizacional para llevarlas a cabo.\n“El desarrollo del clasificador de neumonías será la prioridad inicial dentro de nuestro portafolio de proyectos de IA, dado su alto potencial para mejorar la precisión diagnóstica y optimizar el tiempo de respuesta en urgencias. Este proyecto será evaluado periódicamente para asegurar que se mantenga alineado con los objetivos clínicos y de negocio de nuestra institución.”",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Planteamiento Estratégico</span>"
    ]
  },
  {
    "objectID": "plan-neumonia.html",
    "href": "plan-neumonia.html",
    "title": "8  Plan de Proyecto para la Clasificación de Neumonías con Inteligencia Artificial",
    "section": "",
    "text": "8.1 Introducción\nEl proyecto “Clasificación de Neumonías con IA” tiene como objetivo desarrollar e implementar una herramienta basada en inteligencia artificial que asista a los médicos en la identificación de neumonías a través de radiografías de tórax. Esta solución está diseñada para mejorar la precisión diagnóstica, reducir el tiempo de diagnóstico y optimizar el flujo de trabajo en entornos clínicos. Este documento detalla el plan de proyecto, que será utilizado por todos los colaboradores para garantizar una comprensión compartida de los objetivos, cronograma, roles y responsabilidades, y procesos de evaluación.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Plan de Proyecto para la Clasificación de Neumonías con Inteligencia Artificial</span>"
    ]
  },
  {
    "objectID": "plan-neumonia.html#definición-del-problema",
    "href": "plan-neumonia.html#definición-del-problema",
    "title": "8  Plan de Proyecto para la Clasificación de Neumonías con Inteligencia Artificial",
    "section": "8.2 Definición del Problema",
    "text": "8.2 Definición del Problema\n\n8.2.1 Descripción del Problema Clínico\nLa neumonía es una infección pulmonar común y potencialmente grave, con una alta incidencia a nivel mundial, especialmente en poblaciones vulnerables. El diagnóstico precoz y preciso es crucial para iniciar un tratamiento adecuado y evitar complicaciones. Sin embargo, la interpretación de radiografías de tórax, el principal método de diagnóstico, puede ser subjetiva y está sujeta a variabilidad entre radiólogos, lo que puede llevar a diagnósticos tardíos o incorrectos.\n\n\n8.2.2 Objetivos Específicos del Proyecto de IA\n\nMejorar la Precisión Diagnóstica: Desarrollar un modelo de IA que iguale o supere la precisión de los radiólogos en la detección de neumonía.\nReducir el Tiempo de Diagnóstico: Implementar una solución que permita el análisis de imágenes en tiempo real o casi en tiempo real.\nAsegurar la Integración Clínica: Diseñar el modelo para integrarse sin problemas en los flujos de trabajo clínicos existentes.\nMinimizar los Sesgos y Garantizar la Equidad: Asegurar que el modelo funcione equitativamente en diferentes subgrupos de pacientes.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Plan de Proyecto para la Clasificación de Neumonías con Inteligencia Artificial</span>"
    ]
  },
  {
    "objectID": "plan-neumonia.html#estrategia-del-proyecto",
    "href": "plan-neumonia.html#estrategia-del-proyecto",
    "title": "8  Plan de Proyecto para la Clasificación de Neumonías con Inteligencia Artificial",
    "section": "8.3 Estrategia del Proyecto",
    "text": "8.3 Estrategia del Proyecto\n\n8.3.1 Recolección y Preprocesamiento de Datos\n\nRecolección de Datos:\n\nColaborar con hospitales y clínicas para obtener un conjunto de datos robusto y representativo de radiografías de tórax.\nAsegurar la diversidad en los datos recolectados para incluir diferentes grupos demográficos y clínicos.\n\nPreprocesamiento:\n\nAplicar técnicas de normalización, aumento de datos y segmentación para optimizar la calidad de las imágenes.\nAnonimizar los datos para cumplir con las regulaciones de privacidad.\n\n\n\n\n8.3.2 Desarrollo y Entrenamiento del Modelo\n\nSelección de Arquitectura:\n\nDiseñar una red neuronal convolucional (CNN) ajustada para la tarea de clasificación de neumonías.\nRealizar pruebas de diferentes arquitecturas para identificar la más eficiente.\n\nEntrenamiento del Modelo:\n\nEntrenar el modelo utilizando técnicas de validación cruzada y ajustar los hiperparámetros para maximizar la precisión.\nDocumentar el proceso de entrenamiento para asegurar la reproducibilidad.\n\n\n\n\n8.3.3 Evaluación y Validación\n\nValidación Interna:\n\nEvaluar el modelo en un conjunto de validación interna, asegurando que cumple con los estándares clínicos.\n\nValidación Externa:\n\nProbar el modelo en un conjunto de datos externo para evaluar su capacidad de generalización.\nAjustar el modelo según los resultados de la validación externa.\n\n\n\n\n8.3.4 Implementación y Monitoreo\n\nDespliegue del Modelo:\n\nIntegrar el modelo en los sistemas de información hospitalaria existentes.\nDesarrollar una interfaz de usuario que permita a los radiólogos interactuar con la herramienta de IA.\n\nMonitoreo Continuo:\n\nImplementar un sistema de monitoreo que permita evaluar el rendimiento del modelo en tiempo real.\nEstablecer un plan para el retraining del modelo basado en los datos nuevos y el feedback recibido.\n\n\n\n8.3.4.0.1 Evaluación de Impacto\n\nImpacto Clínico:\n\nMedir la mejora en la precisión y rapidez del diagnóstico.\nEvaluar los resultados clínicos de los pacientes diagnosticados utilizando la herramienta.\n\nFeedback y Mejora Continua:\n\nRecoger feedback continuo del personal médico.\nRealizar mejoras iterativas en el modelo y la interfaz según las necesidades clínicas.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Plan de Proyecto para la Clasificación de Neumonías con Inteligencia Artificial</span>"
    ]
  },
  {
    "objectID": "plan-neumonia.html#roadmap-del-proyecto",
    "href": "plan-neumonia.html#roadmap-del-proyecto",
    "title": "8  Plan de Proyecto para la Clasificación de Neumonías con Inteligencia Artificial",
    "section": "8.4 Roadmap del Proyecto",
    "text": "8.4 Roadmap del Proyecto\n\n8.4.1 Cronograma General\n\nFase 1: Recolección y Preprocesamiento de Datos (0-6 meses)\n\nRecolección de datos en colaboración con hospitales.\nPreprocesamiento y anonimización de datos.\n\nFase 2: Desarrollo y Entrenamiento del Modelo (6-12 meses)\n\nSelección de la arquitectura de la CNN.\nEntrenamiento del modelo y pruebas internas.\n\nFase 3: Validación y Ajustes (12-18 meses)\n\nValidación interna y externa del modelo.\nAjustes finales basados en los resultados de la validación.\n\nFase 4: Implementación Piloto (18-24 meses)\n\nDespliegue en hospitales seleccionados.\nMonitoreo inicial y ajuste en tiempo real.\n\nFase 5: Escalabilidad y Expansión (24-36 meses)\n\nExpansión regional del sistema.\nEvaluación del impacto clínico y optimización continua.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Plan de Proyecto para la Clasificación de Neumonías con Inteligencia Artificial</span>"
    ]
  },
  {
    "objectID": "plan-neumonia.html#equipo-y-perfiles",
    "href": "plan-neumonia.html#equipo-y-perfiles",
    "title": "8  Plan de Proyecto para la Clasificación de Neumonías con Inteligencia Artificial",
    "section": "8.5 Equipo y Perfiles",
    "text": "8.5 Equipo y Perfiles\n\n8.5.1 Experto Clínico\n\nPerfil: Médico especialista en radiología con experiencia en IA.\nResponsabilidades: Definir el problema clínico, evaluar la solución desde una perspectiva médica, y guiar la integración en los flujos de trabajo clínicos.\n\n\n\n8.5.2 Desarrollador de la Solución de IA\n\nPerfil: Ingeniero en informática o científico de datos especializado en visión por computadora.\nResponsabilidades: Desarrollar y entrenar el modelo de IA, asegurar la transparencia y explicabilidad del modelo.\n\n\n\n8.5.3 Líder de Datos Organizacionales\n\nPerfil: Profesional en ciencias de la información o ingeniería de datos con experiencia en datos de salud.\nResponsabilidades: Garantizar la disponibilidad y calidad de los datos, asegurar la compatibilidad y manejo seguro de los datos.\n\n\n\n8.5.4 Experto en MLOps\n\nPerfil: Ingeniero de sistemas o DevOps con experiencia en operaciones de machine learning.\nResponsabilidades: Planificar el despliegue técnico, asegurar la estabilidad y escalabilidad del sistema, y monitorear el rendimiento.\n\n\n\n8.5.5 Líder de IA de la Organización\n\nPerfil: Líder en ciencias de la computación o gestión tecnológica con experiencia en IA.\nResponsabilidades: Evaluar la solución en el contexto de la estrategia organizacional, asegurar la alineación con los objetivos de la organización.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Plan de Proyecto para la Clasificación de Neumonías con Inteligencia Artificial</span>"
    ]
  },
  {
    "objectID": "plan-neumonia.html#presupuesto-y-retorno-de-inversión",
    "href": "plan-neumonia.html#presupuesto-y-retorno-de-inversión",
    "title": "8  Plan de Proyecto para la Clasificación de Neumonías con Inteligencia Artificial",
    "section": "8.6 Presupuesto y Retorno de Inversión",
    "text": "8.6 Presupuesto y Retorno de Inversión\n\n8.6.1 Presupuesto Estimado\n\nRecolección de Datos y Preprocesamiento: $100,000\nDesarrollo y Entrenamiento del Modelo: $150,000\nValidación y Pruebas Clínicas: $100,000\nImplementación y Monitoreo: $100,000\nCapacitación y Soporte Técnico: $50,000\nTotal: $500,000\n\n\n\n8.6.2 Retorno de Inversión (ROI)\n\nProyección de Ahorros:\n\nReducción del tiempo de diagnóstico: 50%\nMejora en la precisión diagnóstica: 20%\nAhorros estimados en costos hospitalarios: $1,000,000 en los primeros 3 años.\n\nPeríodo de Recuperación: 2-3 años",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Plan de Proyecto para la Clasificación de Neumonías con Inteligencia Artificial</span>"
    ]
  },
  {
    "objectID": "plan-neumonia.html#evaluación-y-mejora-continua",
    "href": "plan-neumonia.html#evaluación-y-mejora-continua",
    "title": "8  Plan de Proyecto para la Clasificación de Neumonías con Inteligencia Artificial",
    "section": "8.7 Evaluación y Mejora Continua",
    "text": "8.7 Evaluación y Mejora Continua\n\n8.7.1 Evaluación del Impacto\n\nMétricas de Evaluación:\n\nPrecisión diagnóstica.\nTiempo de diagnóstico.\nSatisfacción del personal médico.\nResultados clínicos de los pacientes.\n\nProceso de Feedback:\n\nReuniones periódicas con el personal médico para recoger feedback.\nImplementación de mejoras basadas en el feedback recibido.\n\n\n\n\n8.7.2 Plan de Mejora Continua\n\nMonitoreo: Sistema de monitoreo continuo para evaluar el rendimiento en tiempo real.\nIteración: Ciclos de mejora basados en datos nuevos y feedback clínico.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Plan de Proyecto para la Clasificación de Neumonías con Inteligencia Artificial</span>"
    ]
  },
  {
    "objectID": "plan-neumonia.html#consideraciones-finales",
    "href": "plan-neumonia.html#consideraciones-finales",
    "title": "8  Plan de Proyecto para la Clasificación de Neumonías con Inteligencia Artificial",
    "section": "8.8 Consideraciones Finales",
    "text": "8.8 Consideraciones Finales\nEste template puede ser entregado a los colaboradores como una guía completa y detallada para la ejecución del proyecto, asegurando que todos los miembros del equipo comprendan sus responsabilidades y el cronograma general del proyecto.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Plan de Proyecto para la Clasificación de Neumonías con Inteligencia Artificial</span>"
    ]
  },
  {
    "objectID": "presentacion.html",
    "href": "presentacion.html",
    "title": "9  Presentación del Proyecto (Pitch)",
    "section": "",
    "text": "9.1 Cómo Preparar un Pitch Efectivo\nPreparar un pitch efectivo para un proyecto de inteligencia artificial (IA), especialmente en el ámbito de la salud, requiere un enfoque estratégico que combine teoría de presentación, técnicas de storytelling, visualización de datos, y una comprensión profunda de los diferentes stakeholders involucrados. A continuación, se desglosan los elementos clave para crear un pitch persuasivo y memorable.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Presentación del Proyecto (*Pitch*)</span>"
    ]
  },
  {
    "objectID": "presentacion.html#presentación",
    "href": "presentacion.html#presentación",
    "title": "9  Presentación del Proyecto (Pitch)",
    "section": "9.2 Presentación",
    "text": "9.2 Presentación\n\n9.2.1 Estructura Clásica del Pitch\n\nInicio Impactante: Captura la atención desde el primer momento. Puedes comenzar con una estadística sorprendente, una anécdota relevante, o una pregunta provocadora que invite a la reflexión.\nProblema y Solución: Define claramente el problema clínico y presenta tu solución de IA como una respuesta directa y efectiva. Asegúrate de articular cómo tu solución aborda específicamente las necesidades críticas identificadas.\nEvidencia y Datos: Respalda tus afirmaciones con datos sólidos y evidencia. Esto incluye resultados preliminares, estudios relevantes, y métricas clave que demuestren la efectividad y el impacto potencial de la solución.\nImpacto: Explica el impacto esperado de tu solución en términos cuantificables, como mejoras en la precisión diagnóstica, reducción de costos, o aumento en la eficiencia operativa.\nLlamado a la Acción: Cierra con un llamado a la acción claro, ya sea solicitando apoyo financiero, colaboración, o la aprobación para proceder a la siguiente fase del proyecto.\n\n\n\n9.2.2 Principios\n\nClaridad: Evita la jerga técnica cuando no sea necesaria. Usa un lenguaje claro y accesible que todos los stakeholders puedan entender, independientemente de su nivel de conocimiento técnico.\nConcisión: Mantén el pitch breve y al punto. Cada palabra debe tener un propósito claro, evitando desviaciones innecesarias.\nCoherencia Visual: Utiliza una presentación visualmente coherente y profesional. La elección de colores, tipografía, y el diseño general debe reforzar tu mensaje, no distraer.\n\n\n\n9.2.3 Comunicación No Verbal\n\nConfianza y Autoridad: Mantén una postura abierta y segura. El contacto visual y los gestos naturales son cruciales para proyectar confianza y autoridad.\nControl del Ritmo: Varía el ritmo de tu presentación para mantener la atención del público. Pausas estratégicas pueden ser usadas para enfatizar puntos clave y permitir que la audiencia procese la información.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Presentación del Proyecto (*Pitch*)</span>"
    ]
  },
  {
    "objectID": "presentacion.html#storytelling-en-presentaciones",
    "href": "presentacion.html#storytelling-en-presentaciones",
    "title": "9  Presentación del Proyecto (Pitch)",
    "section": "9.3 Storytelling en Presentaciones",
    "text": "9.3 Storytelling en Presentaciones\n\n9.3.1 Elementos de Storytelling\n\nNarrativa Central: Construye una narrativa que conecte emocionalmente con la audiencia. Por ejemplo, comienza con una historia sobre un paciente que podría beneficiarse de la solución de IA, lo que humaniza el problema y resalta la importancia de tu proyecto.\nPersonajes y Conflicto: Introduce personajes relevantes, como el médico que enfrenta dificultades en el diagnóstico o el paciente que sufre complicaciones por un diagnóstico tardío. El conflicto debe girar en torno al problema que tu solución de IA resolverá.\nArco Narrativo: Desarrolla la historia siguiendo un arco narrativo clásico (inicio, desarrollo, clímax, y resolución) donde tu solución actúa como la herramienta clave para resolver el conflicto.\nCierre Impactante: Concluye la historia mostrando cómo el uso de la IA transforma la situación, ofreciendo un final positivo y una visión inspiradora del futuro.\n\n\n\n9.3.2 Adaptación del Storytelling Según los Stakeholders\n\nDirectivos y Tomadores de Decisiones: Enfatiza los beneficios estratégicos y financieros. Muestra cómo la solución de IA se alinea con los objetivos de la organización y ofrece un retorno de inversión claro.\nPersonal Clínico: Resalta la mejora en la calidad del cuidado al paciente, la reducción de la carga de trabajo, y cómo la herramienta de IA complementa su expertise clínico.\nInversionistas: Concéntrate en el potencial de mercado, la escalabilidad del proyecto, y el plan de monetización. Utiliza historias de éxito en la industria para ilustrar el crecimiento y la adopción de tecnologías similares.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Presentación del Proyecto (*Pitch*)</span>"
    ]
  },
  {
    "objectID": "presentacion.html#visualización-de-datos",
    "href": "presentacion.html#visualización-de-datos",
    "title": "9  Presentación del Proyecto (Pitch)",
    "section": "9.4 Visualización de Datos",
    "text": "9.4 Visualización de Datos\n\n9.4.1 Importancia de la Visualización de Datos\n\nClaridad y Comprensión: Los datos visualizados correctamente pueden transformar cifras abstractas en conceptos comprensibles. Gráficos, diagramas y tablas bien diseñadas ayudan a la audiencia a captar rápidamente la magnitud del problema y la eficacia de la solución.\nNarración a través de Datos: Los gráficos deben contar una historia. Un gráfico de tendencia que muestra una reducción en los tiempos de diagnóstico antes y después de la implementación de la IA, por ejemplo, cuenta una historia de éxito y mejora.\n\n\n\n9.4.2 Herramientas y Técnicas\n\nGráficos de Barras y Líneas: Útiles para comparar datos antes y después de la implementación del proyecto, o para mostrar tendencias a lo largo del tiempo.\nInfografías: Resumen visualmente los resultados clave y los pasos del proyecto, haciendo la información más accesible y atractiva.\nHeatmaps y Diagramas de Flujo: Pueden mostrar patrones de diagnóstico y los flujos de trabajo mejorados, ilustrando cómo la solución se integra en el entorno clínico.\n\n\n\n9.4.3 Buenas Prácticas en la Visualización\n\nSimplicidad: Evita el exceso de información en un solo gráfico. Cada visualización debe transmitir un mensaje claro sin sobrecargar a la audiencia con datos innecesarios.\nConsistencia de Formato: Usa un formato consistente para todas las visualizaciones, asegurando que los colores, tamaños y estilos sean uniformes a lo largo de la presentación.\nInteractividad: Si es posible, utiliza herramientas de visualización interactivas que permitan a la audiencia explorar los datos por sí mismos durante o después del pitch.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Presentación del Proyecto (*Pitch*)</span>"
    ]
  },
  {
    "objectID": "presentacion.html#enfoque-según-los-stakeholders",
    "href": "presentacion.html#enfoque-según-los-stakeholders",
    "title": "9  Presentación del Proyecto (Pitch)",
    "section": "9.5 Enfoque Según los Stakeholders",
    "text": "9.5 Enfoque Según los Stakeholders\n\n9.5.1 Directivos y Tomadores de Decisiones\n\nFoco: Retorno de Inversión (ROI), reducción de costos, alineación con la estrategia corporativa.\nTip: Utiliza métricas financieras y proyecciones de ahorro a largo plazo para justificar la inversión en el proyecto.\nVisualización Clave: Gráficos de costos antes y después, diagramas de impacto financiero.\n\n\n\n9.5.2 Personal Clínico\n\nFoco: Mejora de la precisión diagnóstica, reducción de la carga de trabajo, facilidad de uso.\nTip: Destaca cómo la solución de IA se integra en sus flujos de trabajo y complementa su expertise, facilitando su labor sin reemplazarlos.\nVisualización Clave: Diagramas de flujo de trabajo, gráficos de precisión y error antes y después de la implementación.\n\n\n\n9.5.3 Inversionistas\n\nFoco: Potencial de crecimiento, escalabilidad, estrategia de monetización.\nTip: Enfatiza la viabilidad comercial y la demanda del mercado, respaldada por datos de la industria y casos de éxito.\nVisualización Clave: Gráficos de proyección de crecimiento, mapas de expansión de mercado, análisis de competencia.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Presentación del Proyecto (*Pitch*)</span>"
    ]
  },
  {
    "objectID": "presentacion.html#expertise-requerido-para-un-pitch-efectivo",
    "href": "presentacion.html#expertise-requerido-para-un-pitch-efectivo",
    "title": "9  Presentación del Proyecto (Pitch)",
    "section": "9.6 Expertise Requerido para un Pitch Efectivo",
    "text": "9.6 Expertise Requerido para un Pitch Efectivo\n\n9.6.1 Conocimiento Técnico\n\nDescripción: Comprender profundamente la tecnología subyacente (en este caso, la inteligencia artificial) es crucial para explicar cómo funciona y por qué es efectiva.\nRecomendación: Involucra a los desarrolladores del proyecto para que expliquen los aspectos técnicos de la solución, respaldados por métricas y datos relevantes.\n\n\n\n9.6.2 Comunicación y Storytelling\n\nDescripción: La habilidad de contar una historia convincente que conecte emocionalmente con la audiencia es clave para mantener su interés y persuadirlos.\nRecomendación: Capacita a los presentadores en técnicas de storytelling y uso de la narrativa para asegurar que el mensaje sea claro y convincente.\n\n\n\n9.6.3 Visualización de Datos\n\nDescripción: Presentar datos complejos de manera comprensible y atractiva requiere habilidades en herramientas de visualización y un entendimiento de cómo los datos pueden apoyar la narrativa.\nRecomendación: Utiliza herramientas como Tableau, Power BI, o Python con librerías como Matplotlib y Seaborn para crear visualizaciones efectivas. Involucra a un analista de datos en el equipo para asegurar la calidad y precisión de las visualizaciones.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Presentación del Proyecto (*Pitch*)</span>"
    ]
  },
  {
    "objectID": "presentacion.html#ejemplo-de-pitch-para-el-proyecto-de-clasificación-de-neumonías.",
    "href": "presentacion.html#ejemplo-de-pitch-para-el-proyecto-de-clasificación-de-neumonías.",
    "title": "9  Presentación del Proyecto (Pitch)",
    "section": "9.7 Ejemplo de pitch para el proyecto de clasificación de neumonías.",
    "text": "9.7 Ejemplo de pitch para el proyecto de clasificación de neumonías.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Presentación del Proyecto (*Pitch*)</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "9  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "colaboracion.html",
    "href": "colaboracion.html",
    "title": "3  Colaboración Interdisciplinaria en Proyectos de IA",
    "section": "",
    "text": "3.1 El Reto de la Colaboración\nLa colaboración interdisciplinaria es clave en todo el proceso. No es suficiente con que cada equipo haga bien su parte; los distintos perfiles deben comunicarse de manera efectiva y entender cómo sus responsabilidades afectan a las demás fases del proyecto. Aquí es donde surgen los retos:\nEl expertise clínico y de medicina es vital en cada fase del proyecto de IA, desde la definición del problema, pasando por la recolección y etiquetado de los datos, hasta la validación, implementación y mejora continua. Los proyectos de IA en salud no pueden tener éxito sin una colaboración profunda entre profesionales clínicos y técnicos, ya que el conocimiento médico es esencial para que los modelos de IA sean útiles y efectivos en el contexto clínico real.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Colaboración Interdisciplinaria en Proyectos de IA</span>"
    ]
  },
  {
    "objectID": "Clasificador.html",
    "href": "Clasificador.html",
    "title": "4  Clasificador de Neumonias con Deep Learning",
    "section": "",
    "text": "4.1 Obtención de Datos\nEn el artículo de Wang et al. (Wang et al. 2017), se presenta la base de datos ChestX-ray8, que incluye benchmarks para la clasificación y localización de enfermedades torácicas comunes.\nPrimero, descargamos los datos de Kaggle\nFuente Original: https://nihcc.app.box.com/v/ChestXray-NIHCC",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Clasificador de Neumonias con Deep Learning</span>"
    ]
  },
  {
    "objectID": "Clasificador.html#obtención-de-datos",
    "href": "Clasificador.html#obtención-de-datos",
    "title": "4  Clasificador de Neumonias con Deep Learning",
    "section": "",
    "text": "Escala del Dataset:\n\n\nEl ChestX-ray8 es una base de datos masiva que contiene 108,948 imágenes de rayos X en vista frontal de 32,717 pacientes únicos. Estas imágenes fueron recolectadas de sistemas de archivado y comunicación de imágenes (PACS) de un hospital, y abarcan un período desde 1992 hasta 2015.\nCada imagen está etiquetada con una o múltiples de ocho enfermedades comunes del tórax (Atelectasia, Cardiomegalia, Derrame, Infiltración, Masa, Nódulo, Neumonía y Neumotórax).\n\n\nEtiquetado mediante Procesamiento de Lenguaje Natural (NLP):\n\n\nLas etiquetas de las enfermedades se extrajeron automáticamente de los informes radiológicos asociados a cada imagen usando técnicas de NLP. Esto permitió generar etiquetas débilmente supervisadas, es decir, etiquetas a nivel de imagen sin la necesidad de anotación manual exhaustiva, lo que sería impracticable a esta escala.\nHerramientas de NLP como DNorm y MetaMap fueron usadas para identificar y normalizar los conceptos de enfermedades a partir de los informes. También se desarrollaron reglas personalizadas para manejar la negación e incertidumbre en las anotaciones.\n\n\nDesafíos Técnicos:\n\n\nDimensiones de las Imágenes: Las radiografías de tórax suelen tener dimensiones grandes (2000x3000 píxeles), lo que presenta desafíos tanto para el almacenamiento como para el procesamiento eficiente de las imágenes.\nVariabilidad en las Etiquetas: Las enfermedades torácicas presentan una gran variabilidad en su apariencia y tamaño dentro de las imágenes, lo que dificulta la clasificación y localización precisas.\n\n\nProcesamiento de Imágenes:\n\n\nLas imágenes fueron redimensionadas a 1024x1024 píxeles para facilitar el procesamiento computacional sin perder detalles significativos.\nSe generaron cuadros delimitadores (B-Boxes) para un subconjunto de imágenes, permitiendo la evaluación de la localización de patologías, aunque el etiquetado denso y detallado a esta escala es inviable.\n\n\n4.1.1 Consideraciones\n\nGran Volumen de Datos:\n\n\nRecolectar y procesar más de 100,000 imágenes radiológicas requiere una infraestructura robusta de almacenamiento y un sistema eficiente de manejo de datos. Esto incluye tanto hardware (servidores, GPUs) como software especializado para manejar grandes volúmenes de datos.\n\n\nAutomatización de Etiquetado:\n\n\nEl etiquetado manual de datos a esta escala es impracticable, por lo que es crucial implementar técnicas avanzadas de procesamiento de lenguaje natural para extraer información relevante de los informes radiológicos. Esto también implica un esfuerzo significativo en la validación de las etiquetas generadas automáticamente para asegurar su precisión.\n\n\nGestión de la Calidad de los Datos:\n\n\nImplementar procedimientos rigurosos para asegurar la calidad de las etiquetas es fundamental, especialmente en entornos clínicos donde la precisión es crítica. Esto incluye la validación cruzada con datos anotados manualmente y la eliminación de etiquetas ruidosas o incorrectas.\n\n\nAdaptación de Modelos de Deep Learning:\n\n\nDado que los modelos preentrenados en conjuntos de datos generales como ImageNet no son directamente aplicables al dominio médico, se requiere ajustar y entrenar modelos de deep learning específicos para el análisis de imágenes médicas, lo que demanda grandes recursos computacionales y expertos en el campo.\n\n\nInfraestructura Computacional:\n\n\nSe necesita una infraestructura computacional poderosa para manejar el entrenamiento de modelos con imágenes de alta resolución, lo que incluye el uso de múltiples GPUs y técnicas como la reducción del tamaño de los lotes de imágenes para manejar las limitaciones de memoria.\n\n\nConsideraciones Éticas y de Privacidad:\n\n\nEl manejo de datos médicos sensibles requiere estrictas medidas de seguridad y anonimización para cumplir con regulaciones de privacidad como HIPAA o GDPR, lo que añade una capa adicional de complejidad al manejo del dataset.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Clasificador de Neumonias con Deep Learning</span>"
    ]
  },
  {
    "objectID": "Clasificador.html#preprocesamiento",
    "href": "Clasificador.html#preprocesamiento",
    "title": "4  Clasificador de Neumonias con Deep Learning",
    "section": "4.2 Preprocesamiento",
    "text": "4.2 Preprocesamiento\nEste notebook realiza varias tareas críticas de preprocesamiento, este se refiere a una serie de pasos realizados para transformar las imágenes de rayos X originales y las etiquetas asociadas a un formato que pueda ser utilizado de manera eficiente por un modelo de inteligencia artificial (IA) o aprendizaje profundo. Estos pasos son fundamentales porque los datos crudos, tal como están, no siempre son ideales para ser introducidos directamente en un modelo.\n\n4.2.1 Exploración\n\n\n\n\n\n\n\n\n\n\npatientId\nx\ny\nwidth\nheight\nTarget\n\n\n\n\n0\n0004cfab-14fd-4e49-80ba-63a80b6bddd6\nNaN\nNaN\nNaN\nNaN\n0\n\n\n1\n00313ee0-9eaa-42f4-b0ab-c148ed3241cd\nNaN\nNaN\nNaN\nNaN\n0\n\n\n2\n00322d4d-1c29-4943-afc9-b6754be640eb\nNaN\nNaN\nNaN\nNaN\n0\n\n\n3\n003d8fa0-6bf1-40ed-b54c-ac657f8495c5\nNaN\nNaN\nNaN\nNaN\n0\n\n\n4\n00436515-870c-4b36-a041-de91049b9ab4\n264.0\n152.0\n213.0\n379.0\n1\n\n\n5\n00436515-870c-4b36-a041-de91049b9ab4\n562.0\n152.0\n256.0\n453.0\n1\n\n\n\n\n\n\n\n\nLeemos el archivo CSV que contiene las etiquetas asociadas a las imágenes. Cada fila contiene un patientId, coordenadas para posibles consolidaciomes (si se detecta neumonía), y la variable Target, que indica si la imagen tiene o no signos de neumonía.\nEl Target es binario (1 = neumonía, 0 = no neumonía). Esta es la variable objetivo que el modelo aprenderá a predecir.\n\n\n\n\n\n\n\n\n\n\npatientId\nx\ny\nwidth\nheight\nTarget\n\n\n\n\n0\n0004cfab-14fd-4e49-80ba-63a80b6bddd6\nNaN\nNaN\nNaN\nNaN\n0\n\n\n1\n00313ee0-9eaa-42f4-b0ab-c148ed3241cd\nNaN\nNaN\nNaN\nNaN\n0\n\n\n2\n00322d4d-1c29-4943-afc9-b6754be640eb\nNaN\nNaN\nNaN\nNaN\n0\n\n\n3\n003d8fa0-6bf1-40ed-b54c-ac657f8495c5\nNaN\nNaN\nNaN\nNaN\n0\n\n\n4\n00436515-870c-4b36-a041-de91049b9ab4\n264.0\n152.0\n213.0\n379.0\n1\n\n\n6\n00569f44-917d-4c86-a842-81832af98c30\nNaN\nNaN\nNaN\nNaN\n0\n\n\n\n\n\n\n\n\nSe eliminan duplicados en las filas que contienen el mismo patientId. Esto es importante porque tener múltiples entradas para el mismo paciente podría causar problemas en el entrenamiento del modelo, como sesgo o sobreajuste.\nCada paciente debe ser representado una única vez en el análisis, para evitar una ponderación excesiva de imágenes de un mismo paciente.\n\n\n\n\n\n\n\n\n\nVisualizamos la distribución de las etiquetas para identificar cualquier desbalance en los datos. Un fuerte desbalance, como un número desproporcionado de imágenes sin neumonía, puede afectar el desempeño del modelo y requerir estrategias como submuestreo o sobrepeso en la clase minoritaria.\nEste gráfico ayuda a entender la prevalencia de neumonía en el conjunto de datos. Si el número de casos de neumonía es mucho menor, eso refleja un reto diagnóstico similar al del mundo real.\n\n\n\n\n\n\n\n\n\nCreamos una cuadrícula 3 x 3 para visualizar 9 imágenes. Esta técnica de visualización ayuda a explorar los datos visualmente, verificando si la calidad de las imágenes es adecuada para el entrenamiento de un modelo.\n\n\n4.2.2 Preprocesamiento de Imagenes\nPara manejar eficientemente nuestros datos , convertimos las imágenes de rayos X almacenadas en formato DICOM a matrices.\nPosteriormente, calculamos la media y la desviación estándar general de los píxeles de todo el conjunto de datos con el propósito de normalización.\nLuego, las imágenes en matrices creadas se almacenan en dos carpetas separadas según su etiqueta binaria: * 0: Todas las radiografías que no muestran signos de neumonía * 1: Todas las radiografías que muestran signos de neumonía\nEstandarizamos todas las imágenes utilizando el valor máximo de píxel en el conjunto de datos proporcionado, 255. Todas las imágenes se redimensionan a 224x224.\n\n\nCode\nsums = 0  # Inicializa la variable para acumular la suma de los píxeles\nsums_squared = 0  # Inicializa la variable para acumular la suma de los cuadrados de los píxeles\n\n# Itera sobre el DataFrame de etiquetas, obteniendo el índice (c) y el ID del paciente (patient_id)\nfor c, patient_id in enumerate(tqdm(labels.patientId)):  \n    # Crea la ruta completa al archivo DICOM correspondiente al paciente\n    dcm_path = ROOT_PATH/patient_id  \n    dcm_path = dcm_path.with_suffix(\".dcm\")  # Añade la extensión \".dcm\" al archivo para que sea legible como DICOM\n    \n    # Lee el archivo DICOM usando pydicom y normaliza los valores de los píxeles dividiendo entre 255\n    dcm = pydicom.read_file(dcm_path).pixel_array / 255  \n    \n    # Redimensiona la imagen, ya que 1024x1024 es demasiado grande para manejar en modelos de Deep Learning.\n    # Cambiamos a una resolución de 224x224.\n    # Convertimos la imagen a tipo float16 para usar menos memoria al almacenar la imagen.\n    dcm_array = cv2.resize(dcm, (224, 224)).astype(np.float16)\n    \n    # Recupera la etiqueta correspondiente a la imagen del paciente (0 para sano, 1 para neumonía)\n    label = labels.Target.iloc[c]\n    \n    # Divide el conjunto de datos en 4/5 para entrenamiento y 1/5 para validación\n    train_or_val = \"train\" if c &lt; 24000 else \"val\"  \n    \n    # Define la ruta de guardado y crea las carpetas necesarias si no existen\n    current_save_path = SAVE_PATH/train_or_val/str(label)  \n    current_save_path.mkdir(parents=True, exist_ok=True)\n    \n    # Guarda el array de la imagen en el directorio correspondiente (train/val y clase 0 o 1)\n    np.save(current_save_path/patient_id, dcm_array)  \n    \n    # Normaliza la suma de los píxeles dividiendo por el número total de píxeles en la imagen (224x224)\n    normalizer = dcm_array.shape[0] * dcm_array.shape[1]  \n    \n    # Solo calcula estadísticas de las imágenes de entrenamiento (no para validación)\n    if train_or_val == \"train\":  \n        # Suma los valores de los píxeles normalizados de cada imagen para calcular la media posteriormente\n        sums += np.sum(dcm_array) / normalizer  \n        \n        # Suma los cuadrados de los píxeles normalizados de cada imagen para calcular la desviación estándar posteriormente\n        sums_squared += (np.power(dcm_array, 2).sum()) / normalizer  \n\n\n\n\n\n\n4.2.2.1 Calcular Media y Desviación Estándar del Dataset\nPara calcular la media y la desviación estándar del conjunto de datos, calculamos la suma de los valores de los píxeles, así como la suma de los valores de píxeles al cuadrado para cada sujeto. Esto permite calcular la media y la desviación estándar general sin mantener todo el conjunto de datos en memoria.\n\n\nCode\nmean = sums / 24000\nstd = np.sqrt(sums_squared / 24000 - (mean**2))\n\nprint(f\"Mean of Dataset: {mean}, STD: {std}\")\n\n\nMean of Dataset: 0.49039623525191567, STD: 0.2479507326197431\n\n\nMedia\n\\(\\mu = \\frac{\\text{sums}}{24000}\\)\nDonde sums es la suma acumulada de los valores de píxeles de todas las imágenes de entrenamiento, y 24000 es el número total de imágenes en el conjunto de entrenamiento.\nDesviación Estándar \\(\\sigma = \\sqrt{\\frac{\\text{sums_squared}}{24000} - \\mu^2}\\)\nDonde: - sums_squared es la suma acumulada de los cuadrados de los valores de los píxeles. - mean**2 es el cuadrado de la media que ya se ha calculado.\nLa normalización es importante para asegurarse de que los valores de los píxeles estén en un rango que permita a las redes neuronales converger más rápido y con mayor precisión. Al normalizar, centramos los valores en torno a la media (0.49) y escalamos con la desviación estándar.\nEste paso asegura que las variaciones en brillo o contraste no afecten el rendimiento del modelo de manera injustificada, permitiendo que la red neuronal se concentre en las características importantes para el diagnóstico, como las consolidaciones pulmonares.\n\n\n\n\nWang, Xiaosong, Yifan Peng, Le Lu, Zhiyong Lu, Mahyar Bagheri, and Ronald M. Summers. 2017. “ChestX-Ray8: Hospital-Scale Chest x-Ray Database and Benchmarks on Weakly-Supervised Classification and Localization of Common Thorax Diseases.” In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). http://openaccess.thecvf.com/content_cvpr_2017/papers/Wang_ChestX-ray8_Hospital-Scale_Chest_CVPR_2017_paper.pdf.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Clasificador de Neumonias con Deep Learning</span>"
    ]
  },
  {
    "objectID": "colaboracion.html#flujo-del-dato",
    "href": "colaboracion.html#flujo-del-dato",
    "title": "5  Colaboración Interdisciplinaria",
    "section": "",
    "text": "Imagen por Dr. Juan I. Barrios\n\n\n\nRecolección de Datos:\n\nEntrada: Imágenes de radiografías de tórax recolectadas de diferentes hospitales y clínicas.\nProceso: Los datos se recolectan en formato DICOM, se anonimizan para proteger la privacidad de los pacientes, y se almacenan en una base de datos central.\n\nPreprocesamiento de Datos:\n\nEntrada: Imágenes de radiografías brutas.\nProceso: Aplicación de técnicas de normalización, aumento de datos, y segmentación para mejorar la calidad y consistencia de las imágenes.\nSalida: Imágenes preprocesadas listas para ser utilizadas en el entrenamiento del modelo.\n\nEntrenamiento del Modelo:\n\nEntrada: Conjunto de datos preprocesados.\nProceso: Las imágenes se utilizan para entrenar la red neuronal convolucional (CNN), ajustando los hiperparámetros para optimizar el rendimiento.\nSalida: Un modelo de IA entrenado que puede clasificar neumonías con un alto grado de precisión.\n\nValidación del Modelo:\n\nEntrada: Modelo entrenado y conjunto de validación independiente.\nProceso: Evaluación del rendimiento del modelo en un conjunto de datos no utilizado durante el entrenamiento para asegurar su capacidad de generalización.\nSalida: Métricas de rendimiento del modelo (precisión, sensibilidad, especificidad).\n\nImplementación y Monitoreo:\n\nEntrada: Modelo validado.\nProceso: Integración del modelo en los sistemas de información hospitalaria, donde se monitorea su rendimiento en tiempo real y se recolectan datos para futuros ajustes.\nSalida: Modelo en producción, utilizado por los radiólogos para apoyar el diagnóstico de neumonía.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Colaboración Interdisciplinaria</span>"
    ]
  },
  {
    "objectID": "colaboracion.html#importancia-de-la-colaboración",
    "href": "colaboracion.html#importancia-de-la-colaboración",
    "title": "5  Colaboración Interdisciplinaria",
    "section": "5.2 Importancia de la Colaboración",
    "text": "5.2 Importancia de la Colaboración\nRol de Diferentes Especialistas en el Proyecto\n\nEspecialista en Radiología (Experto Clínico):\n\nRol: Proporcionar la experiencia clínica necesaria para definir el problema, evaluar la calidad de las imágenes, y guiar el desarrollo del modelo para asegurar que sea clínicamente relevante.\nContribución: Su conocimiento garantiza que el modelo de IA se enfoque en las características críticas para el diagnóstico de neumonía y que la solución sea efectiva en un entorno clínico real.\n\nCientífico de Datos/Ingeniero de IA:\n\nRol: Diseñar y entrenar el modelo de IA, incluyendo la selección de la arquitectura adecuada y el ajuste de hiperparámetros.\nContribución: Su habilidad para transformar datos en un modelo funcional es central para el éxito técnico del proyecto.\n\nIngeniero de Datos (Líder de Datos):\n\nRol: Gestionar la recolección, almacenamiento, y preprocesamiento de los datos. Asegurar la calidad y compatibilidad de los datos utilizados en el entrenamiento del modelo.\nContribución: Su trabajo asegura que el modelo se entrene con datos de alta calidad, lo que es esencial para su rendimiento.\n\nEspecialista en MLOps:\n\nRol: Facilitar la transición del modelo de desarrollo a producción, asegurando su estabilidad, escalabilidad, y monitoreo continuo.\nContribución: Su experiencia permite que el modelo se despliegue eficientemente en el entorno clínico, minimizando el tiempo de inactividad y asegurando que el sistema funcione de manera continua.\n\nLíder de IA (Estratega de IA):\n\nRol: Alinear el proyecto con la estrategia general de IA de la organización, asegurando que el proyecto esté en consonancia con los objetivos organizacionales.\nContribución: Su visión estratégica asegura que el proyecto no solo sea exitoso técnicamente, sino también que aporte valor a largo plazo a la organización.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Colaboración Interdisciplinaria</span>"
    ]
  },
  {
    "objectID": "colaboracion.html#beneficios-y-retos-de-la-colaboración-interdisciplinaria",
    "href": "colaboracion.html#beneficios-y-retos-de-la-colaboración-interdisciplinaria",
    "title": "5  Colaboración Interdisciplinaria",
    "section": "5.3 Beneficios y Retos de la Colaboración Interdisciplinaria",
    "text": "5.3 Beneficios y Retos de la Colaboración Interdisciplinaria\n\nBeneficios:\n\nSinergia de Conocimientos: La combinación de conocimientos clínicos y técnicos permite desarrollar soluciones más efectivas y relevantes.\nInnovación: La interacción entre diferentes disciplinas puede generar nuevas ideas y enfoques que no surgirían en equipos homogéneos.\nMejor Toma de Decisiones: La colaboración entre especialistas permite una evaluación más completa de las posibles soluciones, reduciendo el riesgo de errores.\n\nRetos:\n\nComunicación: Diferentes disciplinas tienen diferentes terminologías y enfoques, lo que puede llevar a malentendidos.\nCoordinación: Coordinar los esfuerzos de un equipo interdisciplinario puede ser complejo, especialmente en proyectos grandes.\nConflictos de Prioridades: Diferentes especialistas pueden tener prioridades y objetivos diferentes, lo que puede generar tensiones dentro del equipo.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Colaboración Interdisciplinaria</span>"
    ]
  },
  {
    "objectID": "colaboracion.html#formación-del-equipo",
    "href": "colaboracion.html#formación-del-equipo",
    "title": "5  Colaboración Interdisciplinaria",
    "section": "5.4 Formación del Equipo",
    "text": "5.4 Formación del Equipo\nSelección de Miembros del Equipo\n\nCriterios de Selección:\n\nExperiencia Relevante: Cada miembro del equipo debe tener experiencia específica en su campo que sea directamente aplicable al proyecto.\nHabilidades de Colaboración: Además de la experiencia técnica o clínica, es esencial que los miembros del equipo sean buenos comunicadores y puedan trabajar bien en equipo.\nAdaptabilidad: Los proyectos de IA pueden evolucionar rápidamente, por lo que es crucial que los miembros del equipo sean capaces de adaptarse a cambios en los objetivos o el enfoque.\n\nDiversidad de Perspectivas:\n\nEs importante que el equipo incluya miembros con diferentes perspectivas, tanto en términos de experiencia técnica como clínica, para asegurar un enfoque holístico.\n\n\n\n5.4.1 Comunicación y Coordinación\n\n5.4.1.1 Herramientas y Estrategias para la Colaboración Efectiva\n\nHerramientas de Colaboración\n\nPlataformas de Gestión de Proyectos (ej., Trello, Asana):\n\nUso: Para organizar tareas, asignar responsabilidades, y hacer seguimiento del progreso del proyecto.\nBeneficio: Facilita la transparencia y la coordinación dentro del equipo, asegurando que todos estén alineados con los objetivos y plazos.\n\nHerramientas de Comunicación (ej., Slack, Microsoft Teams):\n\nUso: Para la comunicación efectiva, tanto para discusiones rápidas como para reuniones más formales.\nBeneficio: Proporciona un espacio centralizado para la comunicación, lo que reduce la pérdida de información y mejora la velocidad de respuesta.\n\nPlataformas de Revisión de Código (ej., GitHub, GitLab):\n\nUso: Para gestionar el desarrollo de software, incluyendo la revisión de código y la colaboración en scripts de análisis de datos.\nBeneficio: Asegura que todos los desarrollos sean revisados por pares y que se mantenga la calidad del código.\n\nDocumentación Colaborativa (ej., Google Docs, Confluence):\n\nUso: Para crear y mantener documentación compartida sobre el proyecto, incluyendo notas de reuniones, decisiones clave, y guías técnicas.\nBeneficio: Proporciona una referencia centralizada que todos los miembros del equipo pueden consultar, asegurando coherencia y continuidad en el proyecto.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Colaboración Interdisciplinaria</span>"
    ]
  },
  {
    "objectID": "Entrenamiento.html",
    "href": "Entrenamiento.html",
    "title": "5  Entrenamiento",
    "section": "",
    "text": "5.1 Transformaciones para Aumentación y Normalización de Datos\nUsamos: - un recorte aleatorio de la imagen y la redimensiona al tamaño original (224x224). - Rotaciones aleatorias entre -5 y 5 grados. - Traslación aleatoria (máximo 5%). - Escalado aleatorio (0.9-1.1 del tamaño original de la imagen).\nCode\ntrain_transforms = transforms.Compose([\n                                    transforms.ToTensor(),  # Convert numpy array to tensor\n                                    transforms.Normalize(0.49, 0.248),  # Use mean and std from preprocessing notebook\n                                    transforms.RandomAffine( # Data Augmentation\n                                        degrees=(-5, 5), translate=(0, 0.05), scale=(0.9, 1.1)),\n                                        transforms.RandomResizedCrop((224, 224), scale=(0.35, 1))\n\n])\n\nval_transforms = transforms.Compose([\n                                    transforms.ToTensor(),  # Convert numpy array to tensor\n                                    transforms.Normalize([0.49], [0.248]),  # Use mean and std from preprocessing notebook\n])\nCode\nbatch_size = 64\nnum_workers = 4\n\ntrain_loader = torch.utils.data.DataLoader(\n    train_dataset, \n    batch_size=batch_size, \n    num_workers=num_workers, \n    shuffle=True, \n    persistent_workers=True \n)\n\nval_loader = torch.utils.data.DataLoader(\n    val_dataset, \n    batch_size=batch_size, \n    num_workers=num_workers, \n    shuffle=False, \n    persistent_workers=True \n)\n\nprint(f\"Tenemos {len(train_dataset)} imagenes de entrenamiento y  {len(val_dataset)} imagenes de validación\")\n\n\nTenemos 24000 imagenes de entrenamiento y  2684 imagenes de validación\n((array([0, 1]), array([18593,  5407])), (array([0, 1]), array([2079,  605])))",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Entrenamiento</span>"
    ]
  },
  {
    "objectID": "Entrenamiento.html#optimizador-y-función-de-pérdida",
    "href": "Entrenamiento.html#optimizador-y-función-de-pérdida",
    "title": "7  Entrenamiento",
    "section": "7.2 Optimizador y Función de Pérdida",
    "text": "7.2 Optimizador y Función de Pérdida\nUsamos el optimizador Adam con una tasa de aprendizaje de 0.0001 y la función de pérdida BinaryCrossEntropy.\n(En realidad, usamos BCEWithLogitsLoss, que acepta directamente los valores predichos sin procesar y calcula la función de activación sigmoide antes de aplicar la entropía cruzada).\nSiéntete libre de pasar un peso diferente de 1 al modelo de Neumonía para usar la función de pérdida ponderada.\n\n\nAccuracy: 0.8457525968551636\nPrecision: 0.7002096176147461\nRecall: 0.5520660877227783\n\n\n/opt/anaconda3/envs/INER/lib/python3.12/site-packages/torch/storage.py:414: FutureWarning:\n\nYou are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n\n\n\n\n\n\n\n\n\n\nTrainer documentation: https://pytorch-lightning.readthedocs.io/en/latest/common/trainer.html",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Entrenamiento</span>"
    ]
  },
  {
    "objectID": "Entrenamiento.html#evaluacion",
    "href": "Entrenamiento.html#evaluacion",
    "title": "7  Entrenamiento",
    "section": "7.3 Evaluacion",
    "text": "7.3 Evaluacion\nDurante la evaluación, el modelo entrenado se prueba en el conjunto de datos de validación para medir su rendimiento. Usamos las siguientes métricas para evaluar el modelo:\n\nPrecisión: La proporción de predicciones correctas sobre el total de predicciones.\nRecall (Sensibilidad): La capacidad del modelo para identificar correctamente las imágenes que contienen signos de neumonía.\nF1-Score: El promedio armonioso de la precisión y el recall. Es una métrica balanceada que toma en cuenta ambos.\nMatriz de confusión: Nos muestra el número de predicciones verdaderas positivas, verdaderas negativas, falsas positivas y falsas negativas.\n\nAdemás, usamos gráficos de la curva ROC (Receiver Operating Characteristic) y el AUC (Área bajo la curva) para visualizar el desempeño del modelo en distintas configuraciones de umbral de decisión.\nEl modelo guardado con la mejor precisión de validación se carga para realizar las evaluaciones finales en el conjunto de datos de prueba.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Entrenamiento</span>"
    ]
  },
  {
    "objectID": "Interpretacion.html",
    "href": "Interpretacion.html",
    "title": "6  Visualizar la decisión del clasificador",
    "section": "",
    "text": "6.1 CAM\nEl objetivo de CAM es visualizar las regiones más importantes de la imagen que influenciaron la decisión del clasificador. El mapa de activación \\(M\\) se calcula utilizando la siguiente fórmula: \\[ M = \\sum_k w_kA_k\\]\nDonde:\n\\(A_k\\) es la salida del último bloque convolucional (es decir, los mapas de características).\n\\(w_k\\) son los pesos asociados de la capa completamente conectada (fully connected).",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Visualizar la decisión del clasificador</span>"
    ]
  },
  {
    "objectID": "plan-estrategico.html#estrategia-para-ia-vs.-estrategia-con-ia",
    "href": "plan-estrategico.html#estrategia-para-ia-vs.-estrategia-con-ia",
    "title": "2  Planteamiento Estratégico",
    "section": "",
    "text": "2.1.1 El Papel de los KPIs\n\nEstrategia en el sector salud: El concepto de estrategia se refiere a cómo las organizaciones priorizan y gestionan múltiples indicadores clave de rendimiento (KPIs) al mismo tiempo.\nInteracción entre KPIs: Los KPIs no funcionan de forma independiente; lo que se hace para optimizar uno puede afectar a otros. Es necesario gestionar estas interacciones para evitar que el énfasis en un área genere efectos negativos en otra.\nIA como herramienta de equilibrio: Los modelos de inteligencia artificial (IA) pueden ayudar a identificar un punto de equilibrio entre varios KPIs, garantizando que se mantenga una calidad adecuada de atención mientras se gestionan otros aspectos como la eficiencia o los costos.\nSupervisión y alineación ética: La implementación de IA debe ser supervisada por los líderes del sector salud para asegurarse de que las decisiones tecnológicas respeten los valores éticos y los objetivos generales de la organización.\n\n\n\n2.1.2 El Papel de los Datos\n\nRelación entre estrategia de IA y estrategia de datos: Una estrategia de IA efectiva depende directamente de una estrategia sólida para los datos. La calidad, cantidad y velocidad de los datos son fundamentales para entrenar modelos de IA de manera adecuada.\nGobernanza de datos: Los hospitales y sistemas de salud deben invertir en una buena gobernanza de datos. Esto significa asegurarse de que los datos sean precisos, completos y se gestionen adecuadamente para su uso en mejorar la atención médica.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Planteamiento Estratégico</span>"
    ]
  },
  {
    "objectID": "plan-estrategico.html#planeación-de-un-proyecto-de-ia",
    "href": "plan-estrategico.html#planeación-de-un-proyecto-de-ia",
    "title": "2  Planteamiento Estratégico",
    "section": "2.2 Planeación de un proyecto de IA",
    "text": "2.2 Planeación de un proyecto de IA\n¿Cómo inicio?\nPara comenzar a planear un proyecto de inteligencia artificial, podemos seguir un enfoque basado en las cuatro fases fundamentales delineadas por Gartner:\n\nEstablecer la Visión del Proyecto de IA\n\nDefinir claramente cómo el proyecto de IA contribuirá a los objetivos generales de la organización. Es crucial establecer desde el inicio cuál es el impacto esperado en términos de precisión diagnóstica, eficiencia en el flujo de trabajo clínico y mejora de los resultados para los pacientes.\n\nIdentificar Barreras Organizacionales y Soluciones\n\nIdentificar y eliminar las barreras que podrían impedir el éxito del proyecto. Esto puede incluir desafíos tecnológicos, falta de habilidades en el equipo, resistencia al cambio, o cuestiones regulatorias.\n\nEvaluar y Mitigar Riesgos\n\nEvaluar los riesgos asociados al proyecto, incluyendo los regulatorios, reputacionales, tecnológicos y relacionados con la competencia. Definir acciones para mitigar estos riesgos.\n\nPriorizar Iniciativas Viables y de Alto Valor\n\nDeterminar qué iniciativas de IA son tanto valiosas como factibles, y priorizarlas en función de su alineación con los objetivos del negocio, la viabilidad técnica y la capacidad organizacional para llevarlas a cabo.\n\n2.2.1 Design Thinking en Healthcare\nDesign Thinking es un enfoque centrado en el ser humano que resulta especialmente valioso en la planificación de proyectos de IA en el sector salud. Este enfoque facilita la creación de soluciones innovadoras que responden directamente a las necesidades de los pacientes y del personal clínico. En el contexto de un proyecto de IA, puedes seguir las siguientes etapas:\n\nEmpatizar: Comprender profundamente las necesidades de los pacientes y los profesionales de la salud que estarán involucrados o beneficiados por el proyecto. Realiza entrevistas o estudios para identificar sus mayores problemas y oportunidades de mejora.\nDefinir: Con base en lo aprendido en la fase de empatía, define claramente los problemas clave que el proyecto de IA resolverá. En el contexto de la salud, esto puede significar la mejora en tiempos de diagnóstico, reducción de errores o personalización del tratamiento.\nIdear: Generar ideas para abordar los problemas identificados. Aquí es útil involucrar a equipos multidisciplinarios, incluidos médicos, científicos, ingenieros y gestores de salud, para asegurar que las soluciones propuestas sean realistas y viables desde una perspectiva clínica y técnica.\nPrototipar: Desarrollar prototipos rápidos que puedan ser probados en entornos reales o simulados. Esto permite iterar rápidamente y mejorar las soluciones antes de su implementación a gran escala.\nEvaluar: Poner a prueba el prototipo con usuarios reales y obtener retroalimentación para afinar el proyecto. En el contexto de IA, esto podría implicar probar un modelo en un entorno clínico para asegurar que las recomendaciones sean útiles y precisas.\n\nEste enfoque de Design Thinking asegura que el proyecto de IA no solo esté alineado con los objetivos técnicos y organizacionales, sino también con las necesidades y expectativas de quienes interactúan con la solución, ya sean pacientes o profesionales de la salud.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Planteamiento Estratégico</span>"
    ]
  },
  {
    "objectID": "colaboracion.html#el-reto-de-la-colaboración",
    "href": "colaboracion.html#el-reto-de-la-colaboración",
    "title": "3  Colaboración Interdisciplinaria en Proyectos de IA",
    "section": "",
    "text": "Interdependencia de Fases: El trabajo de los ingenieros de datos afecta directamente a los resultados de los científicos de datos. Si los datos no están bien preparados, el modelo no será preciso. Del mismo modo, el modelo más preciso puede ser inútil si no se integra bien en una aplicación funcional.\nLenguajes Diferentes: Cada equipo maneja lenguajes y herramientas distintas. Los ingenieros de datos trabajan con herramientas de procesamiento masivo de datos, los científicos de datos con algoritmos y estadística, y los ingenieros de software con sistemas de implementación. Es fundamental que todos estos perfiles encuentren una forma común de comunicarse y de alinear sus objetivos.\nColaboración Continua: El proyecto no termina cuando el modelo se despliega. La evaluación continua del rendimiento del modelo y su ajuste en función de nuevos datos es un esfuerzo continuo que requiere colaboración entre los distintos equipos.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Colaboración Interdisciplinaria en Proyectos de IA</span>"
    ]
  },
  {
    "objectID": "colaboracion.html#beneficios",
    "href": "colaboracion.html#beneficios",
    "title": "3  Colaboración Interdisciplinaria en Proyectos de IA",
    "section": "3.2 Beneficios",
    "text": "3.2 Beneficios\n\nSinergia de Conocimientos: La combinación de conocimientos clínicos y técnicos permite desarrollar soluciones más efectivas y relevantes.\nInnovación: La interacción entre diferentes disciplinas puede generar nuevas ideas y enfoques que no surgirían en equipos homogéneos.\nMejor Toma de Decisiones: La colaboración entre especialistas permite una evaluación más completa de las posibles soluciones, reduciendo el riesgo de errores.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Colaboración Interdisciplinaria en Proyectos de IA</span>"
    ]
  },
  {
    "objectID": "colaboracion.html#formacion-de-equipos",
    "href": "colaboracion.html#formacion-de-equipos",
    "title": "3  Colaboración Interdisciplinaria en Proyectos de IA",
    "section": "3.3 Formacion de Equipos",
    "text": "3.3 Formacion de Equipos\nRol de Diferentes Especialistas en el Proyecto\n\nEspecialistas en Radiología (Experto Clínico):\n\nRol: Proporcionar la experiencia clínica necesaria para definir el problema, evaluar la calidad de las imágenes, y guiar el desarrollo del modelo para asegurar que sea clínicamente relevante.\nContribución: Su conocimiento garantiza que el modelo de IA se enfoque en las características críticas para el diagnóstico de neumonía y que la solución sea efectiva en un entorno clínico real.\n\nCientíficos de Datos/Ingenieros de IA:\n\nRol: Diseñar y entrenar el modelo de IA, incluyendo la selección de la arquitectura adecuada y el ajuste de hiperparámetros.\nContribución: Su habilidad para transformar datos en un modelo funcional es central para el éxito técnico del proyecto.\n\nIngenieros de Datos (Líder de Datos):\n\nRol: Gestionar la recolección, almacenamiento, y preprocesamiento de los datos. Asegurar la calidad y compatibilidad de los datos utilizados en el entrenamiento del modelo.\nContribución: Su trabajo asegura que el modelo se entrene con datos de alta calidad, lo que es esencial para su rendimiento.\n\nEspecialistas en MLOps:\n\nRol: Facilitar la transición del modelo de desarrollo a producción, asegurando su estabilidad, escalabilidad, y monitoreo continuo.\nContribución: Su experiencia permite que el modelo se despliegue eficientemente en el entorno clínico, minimizando el tiempo de inactividad y asegurando que el sistema funcione de manera continua.\n\nLíder de IA (Estratega de IA):\n\nRol: Alinear el proyecto con la estrategia general de IA de la organización, asegurando que el proyecto esté en consonancia con los objetivos organizacionales.\nContribución: Su visión estratégica asegura que el proyecto no solo sea exitoso técnicamente, sino también que aporte valor a largo plazo a la organización.\n\n\n\n3.3.1 Comunicación y Coordinación\n\n3.3.1.1 Herramientas y Estrategias para la Colaboración Efectiva\n\nPlataformas de Gestión de Proyectos (ej., Trello, Asana):\n\n\nUso: Para organizar tareas, asignar responsabilidades, y hacer seguimiento del progreso del proyecto.\nBeneficio: Facilita la transparencia y la coordinación dentro del equipo, asegurando que todos estén alineados con los objetivos y plazos.\n\n\nHerramientas de Comunicación (ej., Slack, Microsoft Teams):\n\n\nUso: Para la comunicación efectiva, tanto para discusiones rápidas como para reuniones más formales.\nBeneficio: Proporciona un espacio centralizado para la comunicación, lo que reduce la pérdida de información y mejora la velocidad de respuesta.\n\n\nPlataformas de Revisión de Código (ej., GitHub, GitLab):\n\n\nUso: Para gestionar el desarrollo de software, incluyendo la revisión de código y la colaboración en scripts de análisis de datos.\nBeneficio: Asegura que todos los desarrollos sean revisados por pares y que se mantenga la calidad del código.\n\n\nDocumentación Colaborativa (ej., Google Docs, Confluence, Notion):\n\n\nUso: Para crear y mantener documentación compartida sobre el proyecto, incluyendo notas de reuniones, decisiones clave, y guías técnicas.\nBeneficio: Proporciona una referencia centralizada que todos los miembros del equipo pueden consultar, asegurando coherencia y continuidad en el proyecto.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Colaboración Interdisciplinaria en Proyectos de IA</span>"
    ]
  },
  {
    "objectID": "colaboracion.html#formación-de-equipos",
    "href": "colaboracion.html#formación-de-equipos",
    "title": "3  Colaboración Interdisciplinaria en Proyectos de IA",
    "section": "3.3 Formación de Equipos",
    "text": "3.3 Formación de Equipos\n\n3.3.1 Rol de Diferentes Especialistas en el Proyecto\n\nEspecialistas en Radiología (Experto Clínico):\n\n\nRol: Proporcionar la experiencia clínica necesaria para definir el problema, evaluar la calidad de las imágenes, y guiar el desarrollo del modelo para asegurar que sea clínicamente relevante.\nContribución: Su conocimiento garantiza que el modelo de IA se enfoque en las características críticas para el diagnóstico de neumonía y que la solución sea efectiva en un entorno clínico real.\n\n\nCientíficos de Datos/Ingenieros de IA:\n\n\nRol: Diseñar y entrenar el modelo de IA, incluyendo la selección de la arquitectura adecuada y el ajuste de hiperparámetros.\nContribución: Su habilidad para transformar datos en un modelo funcional es central para el éxito técnico del proyecto.\n\n\nIngenieros de Datos (Líder de Datos):\n\n\nRol: Gestionar la recolección, almacenamiento, y preprocesamiento de los datos. Asegurar la calidad y compatibilidad de los datos utilizados en el entrenamiento del modelo.\nContribución: Su trabajo asegura que el modelo se entrene con datos de alta calidad, lo que es esencial para su rendimiento.\n\n\nEspecialistas en MLOps:\n\n\nRol: Facilitar la transición del modelo de desarrollo a producción, asegurando su estabilidad, escalabilidad, y monitoreo continuo.\nContribución: Su experiencia permite que el modelo se despliegue eficientemente en el entorno clínico, minimizando el tiempo de inactividad y asegurando que el sistema funcione de manera continua.\n\n\nLíder de IA (Estratega de IA):\n\n\nRol: Alinear el proyecto con la estrategia general de IA de la organización, asegurando que el proyecto esté en consonancia con los objetivos organizacionales.\nContribución: Su visión estratégica asegura que el proyecto no solo sea exitoso técnicamente, sino también que aporte valor a largo plazo a la organización.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Colaboración Interdisciplinaria en Proyectos de IA</span>"
    ]
  },
  {
    "objectID": "colaboracion.html#comunicación-y-coordinación",
    "href": "colaboracion.html#comunicación-y-coordinación",
    "title": "3  Colaboración Interdisciplinaria en Proyectos de IA",
    "section": "3.4 Comunicación y Coordinación",
    "text": "3.4 Comunicación y Coordinación\n\n3.4.0.1 Herramientas y Estrategias para la Colaboración Efectiva\n\nPlataformas de Gestión de Proyectos (ej., Trello, Asana):\n\n\nUso: Para organizar tareas, asignar responsabilidades, y hacer seguimiento del progreso del proyecto.\nBeneficio: Facilita la transparencia y la coordinación dentro del equipo, asegurando que todos estén alineados con los objetivos y plazos.\n\n\nHerramientas de Comunicación (ej., Slack, Microsoft Teams):\n\n\nUso: Para la comunicación efectiva, tanto para discusiones rápidas como para reuniones más formales.\nBeneficio: Proporciona un espacio centralizado para la comunicación, lo que reduce la pérdida de información y mejora la velocidad de respuesta.\n\n\nPlataformas de Revisión de Código (ej., GitHub, GitLab):\n\n\nUso: Para gestionar el desarrollo de software, incluyendo la revisión de código y la colaboración en scripts de análisis de datos.\nBeneficio: Asegura que todos los desarrollos sean revisados por pares y que se mantenga la calidad del código.\n\n\nDocumentación Colaborativa (ej., Google Docs, Confluence, Notion):\n\n\nUso: Para crear y mantener documentación compartida sobre el proyecto, incluyendo notas de reuniones, decisiones clave, y guías técnicas.\nBeneficio: Proporciona una referencia centralizada que todos los miembros del equipo pueden consultar, asegurando coherencia y continuidad en el proyecto.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Colaboración Interdisciplinaria en Proyectos de IA</span>"
    ]
  },
  {
    "objectID": "Entrenamiento.html#transformaciones-para-aumentación-y-normalización-de-datos",
    "href": "Entrenamiento.html#transformaciones-para-aumentación-y-normalización-de-datos",
    "title": "5  Entrenamiento",
    "section": "",
    "text": "Transformaciones en entrenamiento: Se usan para aumentar los datos y evitar sobreajuste. Incluye recortes, rotaciones, traslaciones, y cambios de escala para que el modelo aprenda a generalizar mejor.\nTransformaciones en validación: Solo incluye la normalización, ya que no queremos alterar las imágenes durante la evaluación.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Entrenamiento</span>"
    ]
  },
  {
    "objectID": "Entrenamiento.html#manejo-del-desbalanceo-de-clases",
    "href": "Entrenamiento.html#manejo-del-desbalanceo-de-clases",
    "title": "5  Entrenamiento",
    "section": "5.2 Manejo del Desbalanceo de clases",
    "text": "5.2 Manejo del Desbalanceo de clases\nLas clases están desbalanceadas: hay más imágenes sin signos de neumonía que con neumonía. Existen varias formas de manejar conjuntos de datos desbalanceados:\n\nPérdida ponderada (Weighted Loss)\nSobremuestreo (Oversampling)\nNo hacer nada 🙂",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Entrenamiento</span>"
    ]
  },
  {
    "objectID": "Entrenamiento.html#creacion-del-modelo",
    "href": "Entrenamiento.html#creacion-del-modelo",
    "title": "5  Entrenamiento",
    "section": "5.3 Creacion del Modelo",
    "text": "5.3 Creacion del Modelo\nclass PneumoniaModel(pl.LightningModule):\n    def __init__(self, weight=1):\n        super().__init__()\n        \n        self.model = torchvision.models.resnet18()\n        self.model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n        self.model.fc = torch.nn.Linear(in_features=512, out_features=1)\n        \n        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-4)\n        self.loss_fn = torch.nn.BCEWithLogitsLoss(pos_weight=torch.tensor([weight]))\n        \n        self.train_acc = torchmetrics.Accuracy(task=\"binary\")\n        self.val_acc = torchmetrics.Accuracy(task=\"binary\")\n\nResNet-18: Se modifica para aceptar imágenes en escala de grises (un solo canal, en lugar de tres como en imágenes RGB).\nBinary Cross-Entropy with Logits: Esta función combina la sigmoide y la entropía cruzada en una sola operación, y aquí se ajusta para darle más peso a la clase minoritaria (neumonía).\nAccuracies: Se usan para rastrear la precisión en cada paso de entrenamiento y validación.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Entrenamiento</span>"
    ]
  },
  {
    "objectID": "Entrenamiento.html#entrenamiento-y-validación",
    "href": "Entrenamiento.html#entrenamiento-y-validación",
    "title": "5  Entrenamiento",
    "section": "5.4 Entrenamiento y validación",
    "text": "5.4 Entrenamiento y validación\nEl flujo para el entrenamiento y validación es muy similar:\n\nEn training_step, se calcula la pérdida y la precisión, y se almacenan para usarlas al final de la época.\nEn validation_step, se hace lo mismo pero en el conjunto de validación, sin actualizar los pesos del modelo.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Entrenamiento</span>"
    ]
  },
  {
    "objectID": "Entrenamiento.html#optimizador-y-devolución-de-llamadas",
    "href": "Entrenamiento.html#optimizador-y-devolución-de-llamadas",
    "title": "5  Entrenamiento",
    "section": "5.5 Optimizador y Devolución de Llamadas",
    "text": "5.5 Optimizador y Devolución de Llamadas\n\nSe usa un solo GPU para el entrenamiento. Si hay más GPUs disponibles, se puede ajustar el número.\nModelCheckpoint: Guarda el mejor modelo basado en la precisión de validación.\n\nTrainer documentation",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Entrenamiento</span>"
    ]
  },
  {
    "objectID": "Entrenamiento.html#evaluacion-final",
    "href": "Entrenamiento.html#evaluacion-final",
    "title": "5  Entrenamiento",
    "section": "5.6 Evaluacion Final",
    "text": "5.6 Evaluacion Final\nSe miden métricas como la precisión (accuracy), recall, y la matriz de confusión, que se grafican para analizar el rendimiento del modelo.\n\n\nAccuracy: 0.8457525968551636\nPrecision: 0.7002096176147461\nRecall: 0.5520660877227783\n\n\n/opt/anaconda3/envs/INER/lib/python3.12/site-packages/torch/storage.py:414: FutureWarning:\n\nYou are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n\n\n\n\n\n\n\n\n\n\nLas métricas clave en este tipo de problemas de clasificación binaria (como la detección de neumonía a partir de imágenes de rayos X) son precisión, recall (sensibilidad), matriz de confusión, y exactitud (accuracy).\n\n5.6.1 Exactitud (Accuracy)\nLa exactitud es la proporción de predicciones correctas (tanto verdaderos positivos como verdaderos negativos) con respecto al total de predicciones realizadas.\n\\(\\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}\\)\n\nTP: Verdaderos positivos (correctamente clasificados como con neumonía).\nTN: Verdaderos negativos (correctamente clasificados como sin neumonía).\nFP: Falsos positivos (incorrectamente clasificados como con neumonía).\nFN: Falsos negativos (incorrectamente clasificados como sin neumonía).\n\nEn el caso de nuestro modelo, por ejemplo, un valor de 0.8457 de exactitud indica que el 84.57% de las predicciones fueron correctas, es decir, el modelo clasificó correctamente tanto las imágenes que mostraban neumonía como las que no.\nLimitación: En datasets desbalanceados (como en este caso), la exactitud puede ser engañosa, ya que un modelo puede obtener alta exactitud solo por predecir siempre la clase mayoritaria (en este caso, probablemente las radiografías sin neumonía). Por eso, necesitamos otras métricas como precision y recall.\n\n\n5.6.2 Precisión (Precision)\nDefinición: La precisión mide qué proporción de las predicciones positivas (el modelo dice que hay neumonía) son realmente correctas.\n\\(\\text{Precision} = \\frac{TP}{TP + FP}\\)\nLa precisión de 0.7002 significa que, de todas las veces que el modelo predijo neumonía (incluyendo falsos positivos), el 70.02% de esas predicciones fueron correctas.\n\n\n5.6.3 Recall\nEl recall o sensibilidad mide qué proporción de los casos positivos reales (personas con neumonía) fueron correctamente identificados por el modelo.\n\\(\\text{Recall} = \\frac{TP}{TP + FN}\\)\nEn nuestro modelo, el recall es 0.5520, lo que significa que el modelo identificó correctamente el 55.20% de los pacientes con neumonía.\nUn bajo valor de recall indica que el modelo está fallando en detectar algunos casos de neumonía (falsos negativos). Esto es problemático en contextos clínicos porque significa que algunas personas que realmente tienen neumonía no serán diagnosticadas por el modelo, lo cual es crítico en términos de tratamiento.\n\n\n5.6.4 Matriz de Confusión\nLa matriz de confusión ofrece una representación más detallada de las predicciones del modelo. Se desglosa en cuatro valores clave:\n\nTP (Verdaderos Positivos): Casos de neumonía correctamente clasificados.\nTN (Verdaderos Negativos): Casos sin neumonía correctamente clasificados.\nFP (Falsos Positivos): Casos sin neumonía que fueron clasificados como neumonía.\nFN (Falsos Negativos): Casos de neumonía que fueron clasificados como sanos.\n\nConfusion Matrix:\ntensor([[1936,  143],\n        [ 271,  334]])\n\n1936: Verdaderos negativos (el modelo predijo correctamente que no había neumonía).\n143: Falsos positivos (el modelo predijo neumonía cuando no la había).\n271: Falsos negativos (el modelo no detectó neumonía cuando sí la había).\n334: Verdaderos positivos (el modelo detectó correctamente los casos de neumonía).\n\nUna matriz de confusión como esta te permite ver en qué está fallando el modelo, en este caso, hay más falsos negativos que falsos positivos, lo que es una preocupación en aplicaciones clínicas.\n\n\n5.6.5 5. Matriz de Confusión con Umbral Ajustado\nConfusion Matrix (Threshold=0.25):\ntensor([[1725,  354],\n        [ 136,  469]])\nAl cambiar el umbral de decisión a 0.25, el modelo se vuelve más propenso a clasificar como neumonía, lo que reduce los falsos negativos (de 271 a 136), pero incrementa los falsos positivos (de 143 a 354).\nEste ajuste en el umbral es útil si prefieres minimizar los falsos negativos (casos de neumonía no detectados) a costa de aumentar algunos falsos positivos (personas sanas que son clasificadas incorrectamente como con neumonía).\n\n\n5.6.6 Trade-offs Entre Precisión y Recall:\n\nAlta precisión y bajo recall: El modelo es muy preciso en sus predicciones, pero podría estar perdiendo muchos casos positivos (en este caso, personas con neumonía).\nAlta recall y baja precisión: El modelo detecta la mayoría de los casos positivos, pero también produce más falsos positivos.\n\n\n\n5.6.7 Consideraciones Clínicas:\n\nEn un contexto médico, es crucial mantener un equilibrio entre recall y precisión, dependiendo del impacto de los falsos positivos y falsos negativos.\nEn el caso de neumonía, podrías priorizar un alto recall para no perder casos verdaderos, ya que no detectar neumonía a tiempo puede ser crítico para la salud del paciente.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Entrenamiento</span>"
    ]
  },
  {
    "objectID": "Entrenamiento.html#visualizacion-de-predicciones",
    "href": "Entrenamiento.html#visualizacion-de-predicciones",
    "title": "5  Entrenamiento",
    "section": "5.7 Visualizacion de Predicciones",
    "text": "5.7 Visualizacion de Predicciones\n\n\n\nPredicciones",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Entrenamiento</span>"
    ]
  },
  {
    "objectID": "Interpretacion.html#visualizacion-de-la-arquitectura-de-resnet18",
    "href": "Interpretacion.html#visualizacion-de-la-arquitectura-de-resnet18",
    "title": "6  Visualizar la decisión del clasificador",
    "section": "6.2 VIsualizacion de la Arquitectura de ResNet18",
    "text": "6.2 VIsualizacion de la Arquitectura de ResNet18\n\n\nResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=1000, bias=True)\n)\n\n\nResNet18: Se utiliza como el modelo de base. Aquí, se extraen todas las capas convolucionales antes de la capa de average pooling. Esto es porque queremos acceder a los mapas de características generados por la última capa convolucional para visualizar qué parte de la imagen influyó más en la decisión del modelo.\n\n\n[Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False),\n BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n ReLU(inplace=True),\n MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False),\n Sequential(\n   (0): BasicBlock(\n     (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (relu): ReLU(inplace=True)\n     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n   )\n   (1): BasicBlock(\n     (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (relu): ReLU(inplace=True)\n     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n   )\n ),\n Sequential(\n   (0): BasicBlock(\n     (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (relu): ReLU(inplace=True)\n     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (downsample): Sequential(\n       (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n       (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     )\n   )\n   (1): BasicBlock(\n     (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (relu): ReLU(inplace=True)\n     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n   )\n ),\n Sequential(\n   (0): BasicBlock(\n     (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (relu): ReLU(inplace=True)\n     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (downsample): Sequential(\n       (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n       (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     )\n   )\n   (1): BasicBlock(\n     (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (relu): ReLU(inplace=True)\n     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n   )\n ),\n Sequential(\n   (0): BasicBlock(\n     (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (relu): ReLU(inplace=True)\n     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (downsample): Sequential(\n       (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n       (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     )\n   )\n   (1): BasicBlock(\n     (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n     (relu): ReLU(inplace=True)\n     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n   )\n )]",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Visualizar la decisión del clasificador</span>"
    ]
  },
  {
    "objectID": "Interpretacion.html#modificación-del-modelo-para-cam",
    "href": "Interpretacion.html#modificación-del-modelo-para-cam",
    "title": "6  Visualizar la decisión del clasificador",
    "section": "6.3 Modificación del Modelo para CAM",
    "text": "6.3 Modificación del Modelo para CAM\n\nModificación de ResNet18: Se ajusta la primera capa convolucional para aceptar imágenes de un solo canal (escala de grises), ya que las radiografías no son imágenes RGB. Además, la capa completamente conectada (fc) se modifica para tener una sola salida, ya que este es un problema de clasificación binaria.\nfeature_map: Almacena los mapas de características (features) generados por la última capa convolucional. Estos son esenciales para calcular el CAM.\n\n\n\nSequential(\n  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (2): ReLU(inplace=True)\n  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (5): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (6): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (7): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n)\n\n\n\ndef cam(model, img):\n    with torch.no_grad():\n        pred, features = model(img.unsqueeze(0))\n    features = features.reshape((512, 49))\n    weight_params = list(model.model.fc.parameters())[0]\n    weight = weight_params[0].detach()\n    \n    \n    cam = torch.matmul(weight, features)\n    cam_img = cam.reshape(7, 7).cpu()\n    return cam_img, torch.sigmoid(pred)\n\n\n\n/opt/anaconda3/envs/INER/lib/python3.12/site-packages/pytorch_lightning/utilities/migration/migration.py:208: You have multiple `ModelCheckpoint` callback states in this checkpoint, but we found state keys that would end up colliding with each other after an upgrade, which means we can't differentiate which of your checkpoint callbacks needs which states. At least one of your `ModelCheckpoint` callbacks will not be able to reload the state.\nLightning automatically upgraded your loaded checkpoint from v1.3.4 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint 04-Pneumonia-Classification/weights/weights_3.ckpt`\n/opt/anaconda3/envs/INER/lib/python3.12/site-packages/pytorch_lightning/core/saving.py:191: Found keys that are in the model state dict but not in the checkpoint: ['feature_map.0.weight', 'feature_map.1.weight', 'feature_map.1.bias', 'feature_map.1.running_mean', 'feature_map.1.running_var', 'feature_map.4.0.conv1.weight', 'feature_map.4.0.bn1.weight', 'feature_map.4.0.bn1.bias', 'feature_map.4.0.bn1.running_mean', 'feature_map.4.0.bn1.running_var', 'feature_map.4.0.conv2.weight', 'feature_map.4.0.bn2.weight', 'feature_map.4.0.bn2.bias', 'feature_map.4.0.bn2.running_mean', 'feature_map.4.0.bn2.running_var', 'feature_map.4.1.conv1.weight', 'feature_map.4.1.bn1.weight', 'feature_map.4.1.bn1.bias', 'feature_map.4.1.bn1.running_mean', 'feature_map.4.1.bn1.running_var', 'feature_map.4.1.conv2.weight', 'feature_map.4.1.bn2.weight', 'feature_map.4.1.bn2.bias', 'feature_map.4.1.bn2.running_mean', 'feature_map.4.1.bn2.running_var', 'feature_map.5.0.conv1.weight', 'feature_map.5.0.bn1.weight', 'feature_map.5.0.bn1.bias', 'feature_map.5.0.bn1.running_mean', 'feature_map.5.0.bn1.running_var', 'feature_map.5.0.conv2.weight', 'feature_map.5.0.bn2.weight', 'feature_map.5.0.bn2.bias', 'feature_map.5.0.bn2.running_mean', 'feature_map.5.0.bn2.running_var', 'feature_map.5.0.downsample.0.weight', 'feature_map.5.0.downsample.1.weight', 'feature_map.5.0.downsample.1.bias', 'feature_map.5.0.downsample.1.running_mean', 'feature_map.5.0.downsample.1.running_var', 'feature_map.5.1.conv1.weight', 'feature_map.5.1.bn1.weight', 'feature_map.5.1.bn1.bias', 'feature_map.5.1.bn1.running_mean', 'feature_map.5.1.bn1.running_var', 'feature_map.5.1.conv2.weight', 'feature_map.5.1.bn2.weight', 'feature_map.5.1.bn2.bias', 'feature_map.5.1.bn2.running_mean', 'feature_map.5.1.bn2.running_var', 'feature_map.6.0.conv1.weight', 'feature_map.6.0.bn1.weight', 'feature_map.6.0.bn1.bias', 'feature_map.6.0.bn1.running_mean', 'feature_map.6.0.bn1.running_var', 'feature_map.6.0.conv2.weight', 'feature_map.6.0.bn2.weight', 'feature_map.6.0.bn2.bias', 'feature_map.6.0.bn2.running_mean', 'feature_map.6.0.bn2.running_var', 'feature_map.6.0.downsample.0.weight', 'feature_map.6.0.downsample.1.weight', 'feature_map.6.0.downsample.1.bias', 'feature_map.6.0.downsample.1.running_mean', 'feature_map.6.0.downsample.1.running_var', 'feature_map.6.1.conv1.weight', 'feature_map.6.1.bn1.weight', 'feature_map.6.1.bn1.bias', 'feature_map.6.1.bn1.running_mean', 'feature_map.6.1.bn1.running_var', 'feature_map.6.1.conv2.weight', 'feature_map.6.1.bn2.weight', 'feature_map.6.1.bn2.bias', 'feature_map.6.1.bn2.running_mean', 'feature_map.6.1.bn2.running_var', 'feature_map.7.0.conv1.weight', 'feature_map.7.0.bn1.weight', 'feature_map.7.0.bn1.bias', 'feature_map.7.0.bn1.running_mean', 'feature_map.7.0.bn1.running_var', 'feature_map.7.0.conv2.weight', 'feature_map.7.0.bn2.weight', 'feature_map.7.0.bn2.bias', 'feature_map.7.0.bn2.running_mean', 'feature_map.7.0.bn2.running_var', 'feature_map.7.0.downsample.0.weight', 'feature_map.7.0.downsample.1.weight', 'feature_map.7.0.downsample.1.bias', 'feature_map.7.0.downsample.1.running_mean', 'feature_map.7.0.downsample.1.running_var', 'feature_map.7.1.conv1.weight', 'feature_map.7.1.bn1.weight', 'feature_map.7.1.bn1.bias', 'feature_map.7.1.bn1.running_mean', 'feature_map.7.1.bn1.running_var', 'feature_map.7.1.conv2.weight', 'feature_map.7.1.bn2.weight', 'feature_map.7.1.bn2.bias', 'feature_map.7.1.bn2.running_mean', 'feature_map.7.1.bn2.running_var']\n/opt/anaconda3/envs/INER/lib/python3.12/site-packages/pytorch_lightning/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['loss_fn.pos_weight']",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Visualizar la decisión del clasificador</span>"
    ]
  },
  {
    "objectID": "Interpretacion.html#cam-1",
    "href": "Interpretacion.html#cam-1",
    "title": "6  Visualizar la decisión del clasificador",
    "section": "6.4 CAM",
    "text": "6.4 CAM\n\n\ntorch.Size([1, 512, 1, 1])\ntorch.Size([512])\ntorch.Size([512])\ntorch.Size([512, 49])\n\n\n\n\n\n\n\n\n\n\n\n\nIzquierda: La radiografía original.\nDerecha: La radiografía con el mapa de activación superpuesto. Las áreas más rojas son las que el modelo considera más relevantes para hacer su predicción. Esto ayuda a entender cómo el modelo clasifica a partir de las características aprendidas.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Visualizar la decisión del clasificador</span>"
    ]
  },
  {
    "objectID": "Evaluacion.html",
    "href": "Evaluacion.html",
    "title": "7  Evaluación e Implementación",
    "section": "",
    "text": "7.1  Introducción a la herramienta OPTICA\nUsaremos como ejemplo la herramienta OPTICA para la evaluación de IA en salud (Dagan et al. 2024)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Evaluación e Implementación</span>"
    ]
  },
  {
    "objectID": "Evaluacion.html#introducción-a-la-herramienta-optica",
    "href": "Evaluacion.html#introducción-a-la-herramienta-optica",
    "title": "7  Evaluación e Implementación",
    "section": "",
    "text": "Descripción general:\nOPTICA (Organizational PerspecTIve Checklist for AI solutions adoption) es una herramienta desarrollada para evaluar soluciones de IA desde la perspectiva de organizaciones de salud. Se diseñó para abordar la creciente necesidad de marcos de evaluación prácticos, que tomen en cuenta las características únicas de cada entorno de salud.\nJustificación de su uso:\nLa rápida adopción de herramientas de IA en salud ha mostrado el potencial de mejorar la atención clínica, pero también ha revelado inconsistencias de rendimiento y la falta de adecuación de algunos modelos al ser implementados en diferentes contextos. OPTICA ofrece una evaluación específica al contexto organizacional, asegurando que cada solución esté alineada con las necesidades y recursos locales.\nEstructura de OPTICA:\nLa herramienta se organiza en 13 capítulos divididos en 4 dominios clave:\n\nEspecificación de la necesidad clínica\nExploración de los datos\nEvaluación del desarrollo y desempeño\nPlan de despliegue y monitoreo Cada capítulo contiene varios ítems que deben ser completados por actores específicos, asegurando un enfoque integral.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Evaluación e Implementación</span>"
    ]
  },
  {
    "objectID": "Evaluacion.html#implementación-del-proceso-de-evaluación",
    "href": "Evaluacion.html#implementación-del-proceso-de-evaluación",
    "title": "7  Evaluación e Implementación",
    "section": "7.2 Implementación del proceso de evaluación",
    "text": "7.2 Implementación del proceso de evaluación\n\nElaboración del plan de evaluación:\nPara implementar OPTICA, las organizaciones deben primero designar a los actores clave que participarán en el proceso. Cada uno tendrá la responsabilidad de completar los ítems que les correspondan según su rol (ej. clínico experto, desarrollador de la solución, expertos en seguridad de datos, etc.).\nDesglose de actores clave:\n\nExperto clínico: Lidera la evaluación clínica de la solución y su integración en el flujo de trabajo.\nDesarrollador de la solución: Proporciona detalles sobre el modelo de IA, incluyendo métricas de rendimiento.\nEquipo de datos: Evalúa la disponibilidad y compatibilidad de los datos locales.\nExperto en MLOps: Se encarga de los aspectos técnicos del despliegue de la solución.\nLíder de IA: Supervisa el proceso general y asegura la alineación con la estrategia organizacional.\n\nEtapas del proceso de evaluación: OPTICA organiza el proceso en 7 etapas consecutivas, desde la identificación de la necesidad clínica hasta el monitoreo posterior a la implementación. Cada etapa asegura que se aborden todos los aspectos relevantes de la solución, y permite detener el proceso si se identifica una deficiencia crítica.\n\n\n7.2.1 Estudio de caso\nEl proceso de evaluación para este modelo incluirá los siguientes pasos: 1. Definir la necesidad clínica: ¿Cómo mejora este modelo el proceso actual de diagnóstico de neumonía? 2. Explorar los datos: ¿El conjunto de datos utilizado para entrenar el modelo es representativo de la población que será atendida en el hospital? 3. Evaluar el rendimiento: ¿Cuál es la precisión, sensibilidad y especificidad del modelo? ¿Existen riesgos de sesgos hacia subpoblaciones? 4. Plan de monitoreo: ¿Cómo se controlará el rendimiento del modelo una vez desplegado? - Discusión de resultados:\nAl finalizar el proceso de evaluación, analizaremos si el modelo cumple con los requisitos clínicos y técnicos establecidos. Esto incluye tanto los beneficios esperados (mejoras en la precisión del diagnóstico) como los riesgos potenciales (falta de representatividad en los datos o posibles sesgos).",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Evaluación e Implementación</span>"
    ]
  },
  {
    "objectID": "Evaluacion.html#monitoreo-y-evaluación-continua",
    "href": "Evaluacion.html#monitoreo-y-evaluación-continua",
    "title": "7  Evaluación e Implementación",
    "section": "7.3 Monitoreo y evaluación continua",
    "text": "7.3 Monitoreo y evaluación continua\n\nPlan de monitoreo post-despliegue:\nUn aspecto crítico de la implementación de soluciones de IA es el monitoreo continuo. OPTICA sugiere la creación de planes específicos para reevaluar el rendimiento del modelo en función de las actualizaciones de los datos y las condiciones clínicas.\nIndicadores clave de éxito:\nEstos indicadores deben ser definidos antes del despliegue e incluir métricas clínicas y de usabilidad. Por ejemplo, los tiempos de respuesta de los médicos, la precisión en entornos reales y la satisfacción del usuario final.\n\n\n7.3.1 Desafíos y consideraciones éticas\n\nRiesgos asociados con la IA en salud:\nLas soluciones de IA pueden reproducir sesgos existentes en los datos, lo que puede generar disparidades en la atención. Además, los modelos pueden fallar al ser implementados en nuevas poblaciones, generando errores diagnósticos.\nAspectos legales y de privacidad:\nLos datos clínicos son altamente sensibles y deben manejarse con rigurosos estándares de privacidad y seguridad. El cumplimiento con las normativas locales y nacionales, como la protección de datos personales, es imprescindible para cualquier solución de IA.\n\n\n7.3.1.1 7. Conclusiones\nLa evaluación de las soluciones de IA es un proceso complejo y multidimensional. Requiere la participación de diferentes actores, la consideración de múltiples factores, y un monitoreo continuo para asegurar su éxito en la práctica clínica.\n\n\n\n\nDagan, Noa, Stav Devons-Sberro, Ziv Paz, Lilach Zoller, Adir Sommer, Galit Shaham, Nir Shahar, et al. 2024. “Evaluation of AI Solutions in Health Care Organizations — the OPTICA Tool.” NEJM AI 1 (9): 1–10. https://doi.org/10.1056/AIcs2300269.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Evaluación e Implementación</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Dagan, Noa, Stav Devons-Sberro, Ziv Paz, Lilach Zoller, Adir Sommer,\nGalit Shaham, Nir Shahar, et al. 2024. “Evaluation of AI Solutions\nin Health Care Organizations — the OPTICA Tool.” NEJM AI\n1 (9): 1–10. https://doi.org/10.1056/AIcs2300269.\n\n\nWang, Xiaosong, Yifan Peng, Le Lu, Zhiyong Lu, Mahyar Bagheri, and\nRonald M. Summers. 2017. “ChestX-Ray8: Hospital-Scale Chest x-Ray\nDatabase and Benchmarks on Weakly-Supervised Classification and\nLocalization of Common Thorax Diseases.” In Proceedings of\nthe IEEE Conference on Computer Vision and Pattern Recognition\n(CVPR). http://openaccess.thecvf.com/content_cvpr_2017/papers/Wang_ChestX-ray8_Hospital-Scale_Chest_CVPR_2017_paper.pdf.",
    "crumbs": [
      "References"
    ]
  }
]